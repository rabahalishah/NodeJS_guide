NodeJS is nothing is just a runtime which is used to run the javascript outside of the browser. So who does run the code if not the browser? The answer is V8 engine developed by Google. Where the javascript code will be parse and run in NodeJS. Before NodeJs this was completely impossible to access the file system. After NodeJS this has made javascript to use on server development for website. you can build fast, highly scalable and network applications.

*************Pros of NodeJS
NodeJS is single thread, event driven, non-blocking I/O model which makes it highly lightweight and efficient. 
It is perfect for building highly scalabe and fast apps.

NOTE: in node JS I/O means file accessing and networking like stuff.
**********Use Cases of NodeJS
1. API with databases behind it (preferably NoSQL like MongoDB)
2. Data Streaming apps such as Youtube
3. l-time chat applications
4. ver-side web applications
5. single language for entire stack


**NOTE**: DO NOT USE NODE JS if your server needs high end processing such as image processing, video conversion etc. (CPU intensive tasks). So its better you use RoR, PhP or Python
REPL: Read Eval Print loop


**********Checking global variables in terminal

type node and press enter

now press tab button once or twice

********Checking methods which we can apply on global variables
type any global variable and add . at the end and press tab once or twice


for example:

>String.    (after writting that press tab twice)


***************Modules in Javascript
with the help of node js we can things which we cannot do in the browser such as interacting with the files using file system.

const fs = require('fs');

//here we have imported our module in backend the require function has created an object which is stored in fs variable now we can apply bunch of methods on it.

const textIn = fs.readFileSync('./txt/input.txt', 'utf-8');
console.log('textIn:', textIn);

const textOut = `This is what we know about Avocado: ${textIn}. \nCreated on ${Date.now()}`;
fs.writeFileSync('./txt/output.txt', textOut);

console.log('File has been written!');

This is how we read and write files in JS synchronously.

A gentle reminder of async and sync javascript doe.
sync is a blocking code whereas async is a non blocking code.

Since we all know that NodeJs is made up on single thread paradigm model. which simply means that all the user who are accessing our application are using the single thread. If any of the user used a synchronous code that is blocking all the other users have to wait. In order to prevent this we use async code which also runs a callback function once the code is executed. In JS you will see there is a lot of callback functions.

Example:

const fs = require('fs');
const textIn = fs.readFile('./txt/input.txt', 'utf-8', (err,data)=>{console.log(data)};
console.log('textIn:', textIn);


***************Creating a server
In node JS a server can create by using http module so,
const http = require("http");

const server = http.createServer((req, res) => {
  console.log(req);
  res.end("Hello from the server");
});

// Here when ever the user sends the request to the server the above callback function is gonna run

Server.listen(8000, "127.0.0.1", () => {
  console.log("Listening to request on port 8000");
});

NOTE: port is nothing just a subaddress for the host that is localhost


************Routing in nodeJs

const http = require("http");
const url = require("url");

const server = http.createServer((req, res) => {
  console.log("URL: ", req.url);

  const pathName = req.url;
  if (pathName === "/" || pathName === "/overview") {
    res.end("This is an overview page");
  } else if (pathName === "/product") {
    res.end("This is a product page");
  } else {
    res.writeHead(404, {
        'Content-type': 'text/html',
        'my-own-header': 'This is my own custom header'
    }) 
    // this method is used to send back the status code and headers with a response. but important point to note that
    // the header must be set before sending the res.end response.
    res.end("<h1>404 ERROR, Couldn't found the page</h1>");
  }
});

server.listen(8000, "127.0.0.1", () => {
  console.log("Listening to request on port 8000");
});

// Headers are nothing they are just a piece of information which we send either as a req or res.
// we can have our custom headers as well. There are some general headers such as 'content-type'. This will tell the browser
// what type of content is gonna come as a response.


************APIs
while building APIs simply imagine that the VS code is a server and browser is a client. All responses would be shown to the client

*********Imp methods
req.url //is used to get the the whole url
url.parse(req.url, true) // this is used to get an object which contains all the information about the searching url which also contains the query object.

*************Creating custom module

module.exports = (temp, product) => {
    let output = temp.replace(/{%PRODUCTNAME%}/g, product.productName); // here g means global
    output = output.replace(/{%IMAGE%}/g, product.image); // here g means global
    output = output.replace(/{%PRICE%}/g, product.price); // here g means global
    output = output.replace(/{%FROM%}/g, product.from); // here g means global
    output = output.replace(/{%NUTRIENTS%}/g, product.nutrients); // here g means global
    output = output.replace(/{%QUANTITY%}/g, product.quantity); // here g means global
    output = output.replace(/{%DESCRIPTION%}/g, product.description); // here g means global
    output = output.replace(/{%ID%}/g, product.id); // here g means global
  
    if (!product.organic)
      output = output.replace(/{%NOT_ORGANIC%}/g, "not-organic"); // here g means global
    return output;
  };

// this is how you export you custom module

const replaceTemplate = require('./modules/replaceTemplate')

// And this is how you can import your custom made module


*************NPM
NPM stands for node package manager. Its a CLI registry for installing open source packages. It is one the largest package registry in the world.

***********Dev dependencies
These are the dependencies which are used only for development purposes. These are simply tools which are used while developing an application such as nodemon, module bundler, testing tool etc. Our application do not depend upon them. These dependencies are not included in production.
This is how you install a dev dependency 

>$ npm install nodemon --save-dev

**********Package versioning and updating

a.b.c

where,
a = major version (Huge new release. This may break changes. This may not work with the previous version or code)
b = minor version (new features but these features will not break changes. The new version would be back-ward compatible)
c = patch version (Bug fixes)

-----------

~a.b.c

here ~ this symbol means that we only want to change the patches. Like you open your code base after long time and run npm install it will not update your package to the latest version of the major change but it will only update the patch that is c in this case. It is very safe to use this ~ instead of * which means all versions

^a.b.c

In case of this ^ symbol you will be updated to the wanted or latest version of the app.


There is a command which is used to check the outdated ness of a package

npm outdated

this will give you the information about your package which is installed in your application. That what is its current version what is the accepted version and what is the latest version
-------------------------- Prettier custom configurations
create a file called .prettierrc
and change it like as below as I want to have single quote instead of double qoute for strings.
{
    "singleQuote": true
}


****************************************How web works behind the scenes
When user make a request from the browser by entering the url it contains three component

protocol://domain/resource

https://google.com/maps

In actual what we type that is URL is not the actual address of the server. The address of serve doesn't make sense in reading as its look something like

https://216.58.211:433

so if the url is not the actual address then how a browser is gonna reach our desired server? Here comes DNS (Domain name server) which is a special type of server provided by the ISP (Internet service provider). DNS server is exactly like a phone book.

when a client makes a request the url is send to DNS server where it is matched with the actual address and then the DNS server forward the request to the actual server and then server sends back the response. This whole cycle is called client server Architecture or Client server Request-Response model.


When our website is put on the internet TCP/IP (Transmission control protocol/ Internt Protocol) socket connection is established between client and a server. This connect is kept alive all the time when the data is transferring between the web server and client. These communication protocols actually defines some set of rule that how the data will move on internet.

HTTP is another protocol. Which allows the user to send request to the server and get response back from the server.
The difference between HTTP and HTTPs is that HTTPS is encrypted with TSL or SSL which are some more protocols.

HOW HTTP Request looks like

It has 3 components
Start line: HTTP method (GET,POST etc) + request target + http version
HTTP request headers: (Information)
Request Body: (This 3rd component will be only here if we are sending data to the server that is POST)


HOW HTTP Response looks like
1. Start line: http version + status code + status message
2. HTTP request headers: (Information, the diff. b/w the header of http res and http req is that in case of  http res these are the headers which are specified by the      backend developer) 
3. request Body: (This will specified by the backend developer which data is to send back to the client)

The html file is send back and get scanned by the browser to collect all resources to build the app and show to the client.


The job of TCP is to break the data in thousands of small chunks called packets before send the data. Once the data is reached to the destination it will reassemble all the packets into the original request or response. The main reason of following this protocol is to increase the speed of transfering data.
The loading of data would be much slower if we send the data as a single big chunk which is not a good idea.

Where as the job of the IP is to route the data over the data and to make sure that the data is arrived to the right address.



-----------------Static VS Dynamic 
Static files are simply those files are ready to be served. There is no work done on the server. There is no backend code. You may think that how can a website which is interactive and contains a JS file and still be a static site? Why not dynamic? The word used dynamic on front end is different from the word dynamic used on the backend.

In dynamic websites: there is database and an app like node JS is running on the server which is sending request to the Database and fetching data from database and filling the front end template and made the ready to serve file and then send to browser to display to the client. This whole process is called SSR server side rendering.
NEXTjs is an example of SSR

API-powered website: API website are same as dynamic website but the difference is that we send data to browser in the form of JSON data format. Not any CSS, HTML and JS file. This process is the building of APIs. 
The JSON data which was send from the backend is received on the front end by the frame works like react, angular and then it is rendered on the front end side. This is called consuming APIs. They are also called cliend side Rendering (CSR)
Node is best for making API-powered websites. we can make both kinds of websites with nodejs.

The huge advantage is of api-powered website is that as these are created in node or in any other languages can be consumed by other clients such as native mobile apps than just the browser.

in case of Dynamic SSR websites we cannot do this we can only run them in browser.


*****************NodeJS archtitecture behind the scenes
NodeJS do not only rely on V8 engine of the browser but also rely on some other stuff such as 
libuv (libuv is a multi-platform C library that provides support for asynchronous I/O based on event loops.)
http-parser (for parsing http request)
c-area (For DNS request stuff )
OpenSSL (For cryptography stuff)
zlib (For file compression)


here important point to not that v8 engine and libuv both are written in C++. Here nodeJs is also written in JS & C++ but the beauty is that nodeJS combines them all and provide us the access to C++ function with pure JS.


***************NODE PROCESS and THREADS

Node process is nothing but an instance of a program in execution on a computer
It is always and most important to remember that node always run in single thread. Not matter either there are thousand users or millions of users it is always gonna run in single thread.
This feature of Node makes it easier to block the code. So we always have to take care about the blocking of the code.

**************So what happens when a JS code is executed?
1. When the program is initialize all the top level code is executed first (the code Which is outside of any callback function), all required modules that our app are required and all callbacks are registerd. After that event loop finally starts running. (Event loop is a heart of nodeJS architecture as most of the code is running in event loop).
But there are some task which are too extensive to run in event loop which can block our code. This is the time where thread pool comes in. Which is just like event loop its a library provided by libuv to nodeJS to perform async I/O opertations and to manage event loop.
Libuv provides us 4 or more additional threads (we can configure upto 128 threads) but usually these 4 are enough. These threads combines and form a thread pool. So nodeJS autmatically offload heavy task to the thread pool such as file system APIs, cryptography, compression of files and DNS lookups to match the urls with real IP addresses.
2. All the code which is not the top level code is gonna run in event loop (the code which is inside the callback function is called non-top-level code).

So in short nodeJS do orchestration. It receive the callbacks, execute them in event loop and in case of heavy task it send it to the thread pool.

EVENT LOOP  IN DEPTH:
Event loop has many phases. And each phase has a callback queue.

1st phase Expiration timer callbacks : This phase talks care about the expiration of callbacks (setTimeOut()). In callback queue all code runs behind each other until the node make sure that there is no callback which is left in the callback queue. Once this phase completed node moves to the 2nd phase

2nd phase I/O polling and callbacks: This phase handles stuff related to I/O such as networking and  file accessing. 99% of our code is gonna execute in this phase.

3rd phase setImmediate callbacks: In this phase node runs those callbacks which are supposed to immediately execute right after the execution of first two phases. This phase is basically an advance topic and can be useful in some cases.

4th Close callbacks: This phase includes the callbacks which are supposed to be executed on closing such as shutdown of the websocket etc. 

NOTE: Beside these 4 callback queue there two more callbacks such as PROCESS.NEXTTICK() queue and MICROTASKS queue which are used to resolve promises.
Important point o note that these two special queue do not have to wait to complete the loop of all 4 above mentioned callbacks. These queues get executed after all 4 callbacks each time. Here PROCESS.NEXTTICK() queue  is used for many advance cases.



************WHY DO WE NEED EVENT LOOP?
The answer is simple the we need event loop because nodeJS is single thread no matter how many users are there. So there is a danger of blocking of code thats why we need event loop which makes it more light weight and scalable.

NOTE: ITS YOUR RESPONSIBILTY TO MAKE YOUR CODE NON-BLOCKING.
THIS IS HOW YOU CAN PREVENT YOUR CODE NOT TO BLOCK:

1. Dont use synchronous versions of fcuntions in the fs, crpyto and zlib modules inyour callback functions.
2. Don't perform complex claculations (loops inside loops)
3. Be careful with JSON in large objects.
4. Don't use too complex regular expressions


************EVENT LOOP IN ACTION

const fs = require("fs");

setTimeout(() => console.log("Timer 1 finish"), 0);
setImmediate(() => console.log("Immediate 1 finished"));

fs.readFile("test-file.txt", () => {
    console.log("I/O finished");
    setTimeout(() => console.log("Timer 2 finish"), 0);
    setTimeout(() => console.log("Timer 3 finish"), 3000);
    setImmediate(() => console.log("Immediate 2 finished"));
    process.nextTick(()=> console.log('Process.nextTick'))
});


console.log('Hello from the top level code');

// Ouput: 
Hello from the top level code
Timer 1 finish
Immediate 1 finished
I/O finished
Process.nextTick
Immediate 2 finished
Timer 2 finish
Timer 3 finish


Explanation:
As expected our top level code which is outside of any callback function get executed first after that event loop looked for the callbacks. When ever there is a settimeout function event loop will wait for the polling phase until the timer is expired. Therefore, immediate function ran after the set timeout function.
the important point to note here is that process.nextTick get executed before the immediate and setTimeout The reason is that process.nextTick is a part of microtasks queue not callback queue. And we know that microTasks queue runs after each phase out of all 4 phases. It donot run after all 4 phases of event loop to complete. It will be check every time when each of the phase of event loop will be completed.


Example 3:
const fs = require("fs");
const crypto = require("crypto");
const start = Date.now()

setTimeout(() => console.log("Timer 1 finish"), 0);
setImmediate(() => console.log("Immediate 1 finished"));

fs.readFile("test-file.txt", () => {
  console.log("I/O finished");
  setTimeout(() => console.log("Timer 2 finish"), 0);
  setTimeout(() => console.log("Timer 3 finish"), 3000);
  setImmediate(() => console.log("Immediate 2 finished"));
  process.nextTick(() => console.log("Process.nextTick"));
  console.log("I/O 2nd finished");

  crypto.pbkdf2('password','salt', 100000, 1024, 'sha512', ()=>{
    console.log(Date.now() - start,"Password encrypted");
  })
});

console.log("Hello from the top level code");


// output
Hello from the top level code
Timer 1 finish
Immediate 1 finished
I/O finished
I/O 2nd finished
Process.nextTick
Immediate 2 finished
Timer 2 finish
2057 Password encrypted
Timer 3 finish



// Example 4: Where we will use synchronous version of the code. Here
const fs = require("fs");
const crypto = require("crypto");
const start = Date.now()
process.env.UV_THREADPOOL_SIZE = 1 //here we can manage the number of threads in thread pool. 

setTimeout(() => console.log("Timer 1 finish"), 0);
setImmediate(() => console.log("Immediate 1 finished"));

fs.readFile("test-file.txt", () => {
  console.log("I/O finished");
  setTimeout(() => console.log("Timer 2 finish"), 0);
  setTimeout(() => console.log("Timer 3 finish"), 3000);
  setImmediate(() => console.log("Immediate 2 finished"));
  process.nextTick(() => console.log("Process.nextTick"));
  console.log("I/O 2nd finished");

  crypto.pbkdf2Sync('password','salt', 100000, 1024, 'sha512', ()=>{
    console.log(Date.now() - start,"Password encrypted");
  })
  crypto.pbkdf2Sync('password','salt', 100000, 1024, 'sha512', ()=>{
    console.log(Date.now() - start,"Password encrypted");
  })
  crypto.pbkdf2Sync('password','salt', 100000, 1024, 'sha512', ()=>{
    console.log(Date.now() - start,"Password encrypted");
  })
  crypto.pbkdf2Sync('password','salt', 100000, 1024, 'sha512', ()=>{
    console.log(Date.now() - start,"Password encrypted");
  })
});

console.log("Hello from the top level code");

//output

here the output will be line by line as the code is executing synchronously last four lines of the output will not show until the password is not encrypted this is happening because we are using 3rd party module in callback this means out encryption was not happening inside event loop. While the rest of the code was. The compiler will only pick the code from the event loop once the code in thread pool has completed. As the code in thread pool was not asynchronous therefore compiler had to wait.


Hello from the top level code
Timer 1 finish
Immediate 1 finished
I/O finished
I/O 2nd finished
1826 Password encrypted
3597 Password encrypted
5318 Password encrypted
7070 Password encrypted
Process.nextTick
Immediate 2 finished
Timer 2 finish
Timer 3 finish

// EVENT AND EVENT-DRIVEN ARCHITECTURE:

In NodeJS everything is event driven. 
There is an emitter and there is a listener.

For example

server.on('request', callback)

here whenever user make the request the server.on emit the event and here 'request' will listen it. This is how emitting and listening the event cycle goes.


***********STREAMS
Streams is also one of the fundamental concept in CS. Its basically a concept in which we process (read and write) the data by pieces instead of processing the whole data once.
Perfect application of this concept is in Youtube and netflix where the videos are streamed as their piece of data is downloaded. Instead of waiting for the whole file to download and play streams plays as the data is downloading.

streams are perfect for handling large volumes
TYPES OF STREAMS
In NodeJS there are 4 types of streams
1. Readable Streams: Streams from which we can consume data such as http requests, fs read streams, pipe(), read() functions.
2. Writable Streams: (most imp) Streams from which we can write data such as http requests, fs read streams, write(), end() functions.
3. Duplex Streams: Streams that are both readable and writable such as web sockets.
4. Transform Streams: Streams that transform data as it is written or read.


***********STREAMS IN ACTION
const fs = require('fs');
const server = require('http').createServer();

server.on('request', (req, res) => {
  // sol1 : without stream
  fs.readFile("test-file.txt", (err, data) => {
    if (err) console.log(errr);
    res.end(data);
  });

  // sol2: Stream

  const readable = fs.createReadStream('test-file.txt');
  
  readable.on('data', (chunk) => {
    res.write(chunk);
  });
  readable.on('end', () => {
      res.end();
    });
    readable.on('error', (error) => {
        console.log(error);
        res.statusCode = 500;
        res.end('File not found!');
      });
      
  //sol3: 
    const readable = fs.createReadStream('test-file.txt');
    readable.pipe(res)
    // readableSource.pipe(writeableDestination)


});

server.listen(8000, '127.0.0.1', () => {
  console.log('Listening...');
});


EXPLANATION: Here in this example we are trying to read a large txt file and send it as a response to the client on the browser. The solution 1 is the worst solution of sending and reading such large text file as this will eventually make your app to crash. 

In solution two we are reading data in the form of chunk by making the data a readable stream. This solution is good but there is special case in which reading the data from the file is fast but sending response is not as faster as we are reading the data. This situation is called back pressure. In order to avoid this we just have to you use pipe method on our readableSoure that is text file in this case. This is solution 3 which is best for this case.


///////////////////// HOW REQUIRE MODULE WORKS	
IN node js as we all know if we want to export any module we simple do

module.exports = yourFunctionName;

we can also do:

module.exports = anyFunction

we can also do:

exports.anyName = () => {}

what is Caching
// in path file
console.log("I am happpy")
module.exports = () => console.log("I am sad");


// In other file
require('./path)()
require('./path)()
require('./path)()

//output
I am happpy
I am sad
I am sad
I am sad


// the  reason by I am happy console only 1 time due to caching. Node stores in somewhere in memory and console only once no matter how many time it is get imported. Where as I am sad was console 3 times because it was calling by a function 3 times.



****************************Express
Express is a NodeJS frame work which means it is build on the top of NodeJs. It includes complex routing, easier handling of request and responses, middleware, SSR etc. It makes easier for us to organize our applicaiton in MVC architecture.
Express automically send some pre-defined headers. We do not manually defined the headers in some cases.

************Postman
Postman is a tool which is used for API testing. It works like browser (Client side) but it do not render HTML.


*************Express Natrous Project

One thing that I would like to mention before making project in Node js that is "Web is all about sending request and responses"

Standard is that we firt make an app.js file where we do all our configuration like creating app in express, defining routes and ports and listening to the server.

************Setting UP express and basic routing
// basic configuration in app.js

const express = require('express')

const app = express()

app.get('/', (req,res)=>{
    res.status(200).send('Hello from server side!')
})

const port = 3000;
app.listen(port,()=>{
    console.log(`Server is running on port ${port}`);
})

NOTE: Since its a good practice and easy to send json file so instead of using res.send we will use res.json({key:value}) as below:

const express = require('express');

const app = express();

app.get('/', (req, res) => {
  res.status(200).json({ message: 'Hello from server side!', app: 'Natours' });
});
app.post('/', (req, res) => {
  res.status(200).json({ message: 'You can post data to this endpoint', app: 'Natours' });
});

const port = 3000;
app.listen(port, () => {
  console.log(`Server is running on port ${port}`);
});




Always remember, you can read data from Client side using endpoint/URL defined with GET method. Similarly, YOu can send data from Client side to the endpoint/URL which is defined with POST method.


***********REST API architecture
REST stands for Representaion States Transfer, It is basically a way of building API logic so they are easy to consume for the user. In order to build APIs following the principle of REST architecture we have to follow some rules:
1. Separate API into logical resources.
2. Expose/Show structured, resource-based URLs
3. Use HTTP methods
4. Send data as JSON format
5. Must be stateless

Let understand all 5 principles one by one:
1. Separate API into logical resources: Here resource means any kind of information such as reviews, tours etc. First separate all the information in logical way. Here logical means name shoudl make sense.

2. Expose structured & 3. Use HTTP methods, resource-based URLs: The address of our URLs should be resource based and do not include any action in their name such as /getNewTour, /addNewTour, /deleteTour, /updateTour etc. Don't do this. It should not be look like this
so instead of this our URLs should look like this:

GET   /tours  (for getting the tours)
POST  /tours   (for adding new tours)
DELETE /tours   (for deleting the tours)
PUT or PATCH /tours    (for updating the tours the difference b/w put and patch is that put is to update the entire object and patch is used to update the piece of an object)

here you have notice that our endpoints are same put our HTTP methods are different. Our URL contains only names not actions. Our actions are defined by our http method.

in case of getting or approaching to a specifi user or a specific tour we have to get their by a unique id or unique information. for example:
GET   /tours/46  (for getting the tour having id 46)

4. Send data as JSON format:
JSON is very lightweight to transfer information. In JSON all keys are strings. Values can be anything such as strings, number, boolean etc.
The good practice is that we use Jsend. In this format we use a status and wrap all data in data object

{
"status":"succcess",
"data": {
	"id":5,
	"name":"John",
	}
}

5. API Must be stateless
Means all state must be handled on client side. This means that each request must contain all the necessary information to process a certain request. The server should not have to remember previous requests on the server.

For example:
If we are on currently page 5 and we have made an API URL that is /nextPage

so in order to go to page 6 server shoudl remember current page as nextPage = currentPage + 1. This is bad. We should avoid it in REST architecture. Instead you should simply pass a number
/page/6


*****************Lets start building APIs

I will just mention here best practices and things which are important only

app.get('/api/v1/tours', (req, res) => {
  res.status(200).json({
    status: 'success',
    results: tours.length,
    data: {
      tours: tours,
    },
  });
});

here making APIs URL with /api/v1/tours
here v1 is the version of the api. It is a good practice to add version of your API in URL as it is important while making changes to it to make version 2.

*******Handling POST request
app.post('/api/v1/tours', (req, res) => {
	console.log(req.body);
    res.status(200).send('Done') // You always have to send response back to complete req-res cycle
})

here in post request the data is send from the client to the server. So that data should be available in req parameter right? but Express does not put that body data on the req parameter. So in order to have that availble we use a simple middleware on top of the express app. (Middleware is simply a function that modifies the incoming request data. It is called middleware as it stands between the request and the response)

const app = express();
app.use(express.json())


****Sending data from the postman (Client side) to the server
Select HTTP POST  method and paste your end point and go to body tab and select raw and JSON
now write you JSON object
{
    "name": "Test Tour",
    "duration": 10,
    "difficulty": "easy"
}



**JavaScript**
const newTour = Object.assign({ id: newId }, req.body);

// This is how you merge two objects in javascript.



***Saving data to our finctional database (folder or .json file)

app.post('/api/v1/tours', (req, res) => {
  console.log(req.body);
  const newId = tours[tours.length - 1].id - 1;
  const newTour = Object.assign({ id: newId }, req.body);
  tours.push(newTour);

  
  fs.writeFile(`${__dirname}/dev-data/data/tours-simple.json`, JSON.stringify(tours), err => {
    res.status(201).json({
        status: 'success',
        data : {
            tour : newTour
        }
    })

  })
});


// Here status 201 means created

***********Responding to URL parameters
If you want to add a variable in your url this is how you can do that

app.get('/api/v1/tours/:id', (req, res) => {
    console.log(req.params);
  res.status(200).json({
    status: 'success',
  });
});

// so here If you would access this endpoint with any id after /api/v1/tours/ such as /api/v1/tours/25

you will get

{ id: '25' }

you can also do something like this 
app.get('/api/v1/tours/:id', (req, res) => {
  console.log(req.params);
  const id = req.params.id * 1;
  const tour = tours.find((el) => el.id === id);
  res.status(200).json({
    status: 'success',
    data: {
      tour: tour,   
    },
  });
});


So on accessing 127.0.0.1:3000/api/v1/tours/69/68/67
you can get
{ id: '69', x: '68', y: '67' }


**JS: const id = req.params.id * 1; //This is how you convert a string into a number. Type coersion JS automatically converts a string number into a number one multiplying it by any number. Here find method loop over each element and return a new array wo satisfay the logic in the callback function.

*************Handling patch request
app.patch('/api/v1/tours/:id', (req, res) => {
    if (req.params.id *1 > tours.length) {
        return res.status(404).json({
            status: 'fail',
            message: 'Invalid ID'
        })
    }
  res.status(200).json({
    status: 'success',
    data: {
      tour: '<update tour here>',
    },
  });
});

This is how we deal with a basic patch request.


****************Handling Delete request
app.patch('/api/v1/tours/:id', (req, res) => {
    if (req.params.id *1 > tours.length) {
        return res.status(404).json({
            status: 'fail',
            message: 'Invalid ID'
        })
    }
  res.status(204).json({
    status: 'success',
    data: null,
  });
});

This is how we deal with a basic delete request.

**************Cleaning the code

// separate all login of all HTTP methods into a separate function and then call them respectively.

app.get('/api/v1/tours', getAllTours);
app.get('/api/v1/tours/:id', getTour);
app.post('/api/v1/tours', createTour);
app.patch('/api/v1/tours/:id', updateTour);
app.delete('/api/v1/tours/:id', deleteTour);

where getAllTours is:
const getAllTours = (req, res) => {
  res.status(200).json({
    status: 'success',
    results: tours.length,
    data: {
      tours: tours,
    },
  });
};

and so on of rest of the funtions

*************Cleaning the code part 2

now in order to overcome the repeatability of routes we can do something like this

app.route('/api/v1/tours').get(getAllTours).post(createTour);
app
  .route('/api/v1/tours/:id')
  .get(getTour)
  .patch(updateTour)
  .delete(deleteTour);

// This is exactly same as:

// app.get('/api/v1/tours', getAllTours);
// app.get('/api/v1/tours/:id', getTour);
// app.post('/api/v1/tours', createTour);
// app.patch('/api/v1/tours/:id', updateTour);
// app.delete('/api/v1/tours/:id', deleteTour);


***************Middleware and Request Response cycle

Middleware is nothing its simple a req-res Obj or you can say its a function which get executed in between sending the response and receiving the request.
In express everthing is middleware. Even routes functions are middleware. All middleware in our app is called middleware stack.

The order of middleware in a middleware stack is depent on the order they are declared. The one who is defined earlier will get executed first. So the order of the code matters a lot in Express. You have noticed in many of the code that next() function is executed at the end of every middleware. In all middleware functions we have access to next() function just same as we have access to req, res functions in HTTP methods.

So when the next() function is executed we call the next middleware with the exact same req-res obj. Its like pipeline through which our receiving request obj goes through. Moreover, in the last middleware we do not call next function we actually send response back to client.

************Creating our own Middleware


app.use((req, res, next) => {
  console.log('Hello from the middleware!');
  next();
});


// This is the most basic middleware function which will run whenever we will make an API request on any route. This is because we didnt specified any route and defined this middlerware at the top of all routes thats why all routes after the declaration of this middleware will call this middleware on making request. As we know that in middleware the order of it declaration matters a lot. If we define it at the end after the all routes. Then this was not gonna call on any api request.

**EXP2**
app.use((req, res, next) => {
  req.requestTime = new Date().toISOString();
  next();
});

const getAllTours = (req, res) => {
  console.log(req.requestTime);
  res.status(200).json({
    status: 'success',
    requestAt: req.requestTime,
    results: tours.length,
    data: {
      tours: tours,
    },
  });
};


*************Using 3rd party middleware

npm install morgan
HTTP request logger middleware for node.js. Its is a very simple middlerware. On making any HTTP request this will give you a log of that request. Here log includes, HTTP Method, API endpoint,status code, time it took to send back response, and size of the response in bytes.

Here is an example of morgan log:  GET /api/v1/tours 200 4.679 ms - 8680

const morgan = require('morgan');
app.use(morgan('dev'));

//This Morgan middleware just like normal middleware returns a function (req, res, next)




***************Creating Routes for users
app
   .route('/api/v1/users')
   .get(getAllUsers)
   .post(createUser);
app
  .route('/api/v1/users/:id')
  .get(getUser)
  .patch(updateUser)
  .delete(deleteUser);


****************Creating and mounting multiple routes

// Routes for tours
app.route('/api/v1/tours').get(getAllTours).post(createTour);
app
  .route('/api/v1/tours/:id')
  .get(getTour)
  .patch(updateTour)
  .delete(deleteTour);

//Routes for users
app.route('/api/v1/users').get(getAllUsers).post(createUser);
app
  .route('/api/v1/users/:id')
  .get(getUser)
  .patch(updateUser)
  .delete(deleteUser);

// Here we have to note that till this point all our routes, controller for both users and tours are in the same file. Now its time to move them in a separate file as it is a good practice and will allow us to manage and scale our code. But before doing that we have to define separate route for users and tours. Here in this case both are sunning on same  route that is app routs. So in order to separate it lets use a middleware for creating separate routes


This is how you do that:

const tourRouter = express.Router();
app.use('/api/v1/tours', tourRouter); //This is basically called Mouting the router
tourRouter.route('/').get(getAllTours).post(createTour);
tourRouter.route('/:id').get(getTour).patch(updateTour).delete(deleteTour);

here we are using middlerware for a specific route that is /api/v1/tours now this will become your parent route.


************File structuring

So create a routes folder in the root directory
and create two files:
1. tourRoutes.js
2. userRoutes.js

Now put the respective route code in respective files except middlewares. keep your middleware in your app.js file and remember that it is a standard.
Moreover in tourRoutes.js we do no export module with tourRouter we will export module with Router name as
const Router = express.Router();
module.exports = Router;

same for userRoutes.js


now create a controller folder and create two new files called

1. tourController.js
2. userController.js

and paste all your controller functions here and export them all as

exports.myFunction => {}
exports.myFunction2 => {}

and so on

const controllerFunctions = require('./path');

// how to use?

controllerFunction.myFunction
controllerFunction.myFunction2
// This is how you use these functions in other files


Create a server.js on  the level of app.js and run server there

// In app.js
.. rest of the code
module.exports = app;


// In server.js
const app = require('./app')
const port = 3000;
app.listen(port, () => {
  console.log(`Server is running on port ${port}`);
});



Now lets summarize our file structure

we have

1. server.js (Our server is running here)
2. app.js (All configurations such as middlewares, mounting routes etc.)
3. routes Folder (All routes/subapp)
4. Controller Folder (All logic or handler function of routes are here)


Always follow this standard

Now to summarise let me show you the code in each file

// 1. In Server.js

const app = require('./app')
const port = 3000;
app.listen(port, () => {
  console.log(`Server is running on port ${port}`);
});


// 2. app.js

const express = require('express');
const morgan = require('morgan');
const tourRouter = require('./routes/tourRoutes')
const userRouter = require('./routes/userRoutes')

const app = express();

// middlewares
app.use(morgan('dev'));

app.use(express.json());

app.use((req, res, next) => {
  req.requestTime = new Date().toISOString();
  next();
});

// Mounting the routes
app.use('/api/v1/tours', tourRouter);
app.use('/api/v1/users', userRouter);

module.exports = app;


// 3. In Route Folder
//In tourRoute.js

const express = require('express');
const tourController = require('../controllers/tourController');
const router = express.Router();

router.route('/')
  .get(tourController.getAllTours)
  .post(tourController.createTour);
router.route('/:id')
  .get(tourController.getTour)
  .patch(tourController.updateTour)
  .delete(tourController.deleteTour);

module.exports = router;

//In userRoute.js

const express = require('express');
const userController = require('../controllers/userController');
const router = express.Router(); //Its a convention to call it router instead of userRouter

router.route('/')
  .get(userController.getAllUsers)
  .post(userController.createUser);
router.route('/:id')
  .get(userController.getUser)
  .patch(userController.updateUser)
  .delete(userController.deleteUser);

module.exports = router;


// 4. In Controller folder
// tourController.js
const fs = require('fs');
const tours = JSON.parse(
  fs.readFileSync(`${__dirname}/../dev-data/data/tours-simple.json`)
);

exports.getAllTours = (req, res) => {
  console.log(req.requestTime);
  res.status(200).json({
    status: 'success',
    requestAt: req.requestTime,
    results: tours.length,
    data: {
      tours: tours,
    },
  });
};

exports.getTour = (req, res) => {
  console.log(req.params);
  const id = req.params.id * 1;

  const tour = tours.find((el) => el.id === id);
  if (!tour) {
    return res.status(404).json({
      status: 'fail',
      message: 'Invalid ID',
    });
  }
  res.status(200).json({
    status: 'success',
    data: {
      tour: tour,
    },
  });
};

exports.createTour = (req, res) => {
  console.log(req.body);
  const newId = tours[tours.length - 1].id + 1;
  const newTour = Object.assign({ id: newId }, req.body);
  tours.push(newTour);

  fs.writeFile(
    `${__dirname}/dev-data/data/tours-simple.json`,
    JSON.stringify(tours),
    (err) => {
      res.status(201).json({
        status: 'success',
        data: {
          tour: newTour,
        },
      });
    }
  );
};

exports.updateTour = (req, res) => {
  if (req.params.id * 1 > tours.length) {
    return res.status(404).json({
      status: 'fail',
      message: 'Invalid ID',
    });
  }
  res.status(200).json({
    status: 'success',
    data: {
      tour: '<update tour here>',
    },
  });
};

exports.deleteTour = (req, res) => {
  if (req.params.id * 1 > tours.length) {
    return res.status(204).json({
      status: 'fail',
      message: 'Invalid ID',
    });
  }

  res.status(204).json({
    status: 'success',
    data: null,
  });
};
	

// In userController.js

exports.getAllUsers = (req, res) => {
    res.status(500).json({
      status: 'error',
      message: 'This route is not yet defined',
    });
  };
  exports.createUser = (req, res) => {
    res.status(500).json({
      status: 'error',
      message: 'This route is not yet defined',
    });
  };
  exports.getUser = (req, res) => {
    res.status(500).json({
      status: 'error',
      message: 'This route is not yet defined',
    });
  };
  exports.updateUser = (req, res) => {
    res.status(500).json({
      status: 'error',
      message: 'This route is not yet defined',
    });
  };
  exports.deleteUser = (req, res) => {
    res.status(500).json({
      status: 'error',
      message: 'This route is not yet defined',
    });
  };


**************Param middleware function

Param middle ware is a middleware which is run only for certain parameters in our URL. Here in our case we have id in our URL.
Since we have created our routes folder now
// In tourRoute.js

const router = express.Router();
router.param('id',(req, res, next, val)=>{
 console.log(`The Value of Id is: ${val}`);
  if (req.params.id * 1 > tours.length) {
    return res.status(404).json({
      status: 'fail',
      message: 'Invalid ID',
    });
  }
  next();
}


This req.param takes two argument one is our string which is in the URL (In our case its Id it will not work if we miss spelled Id). The second argument is callback function. The val argument in callback will have access to the value of id which the user is putting in the URL. 

In our app we are using this middleware for checking the id whether its valid or not. This middleware will run when the a url with any id will be called. 
It is standar to define the logic of callback function in controller function.

const tourController = require('../controllers/tourController');
router.param('id', tourController.checkID);



We are using middlewares instead of simple functions the reason behind this fact is that its a philosophy of express to use middlewares as much as we can.


*************Chaing middleware

One thing I would like to clear is that in our controller.js getTour, createTour all these functions are also middlewares.


Okay so this is how you chain or connect your middlware.

// In tourRoute.js
const express = require('express');
const tourController = require('../controllers/tourController');
const router = express.Router();

router.param('id', tourController.checkID);

router.route('/')
  .get(tourController.getAllTours)
  .post(tourController.checkBody, tourController.createTour); //Here checkBody is our middleware
router.route('/:id')
  .get(tourController.getTour)
  .patch(tourController.updateTour)
  .delete(tourController.deleteTour);

module.exports = router;

// Here syntax router.route.post(middlware, 2nd Middlware)
router.route.post(tourController.checkBody, tourController.createTour); //Here checkBody is our middleware which is responsible for checking name and price in the incoming data from the user before creating the new user.
remember that in our controller.js getTour, createTour all these functions are also middlewares.

// In tourController.js
exports.checkBody = (req, res, next) => {
  if (!req.body.name || !req.body.price) {
    return res.status(400).json({
      status: 'fail',
      message: 'Missing Name or price',
    });
  }
  next();
};

// Here if the confition is true then it will send back the response and will complete the req-res cycle. In case of false confition code inside if condition will not run and it will call the next() to call the next middleware that is createTour in this case.



*****************Accessing static files from our local machine using a new middleware

app.use(express.static(`${__dirname}/public`));


now go to the browser
http://127.0.0.1:3000/overview.html

or

http://127.0.0.1:3000/filename


*******Environmental variable
how to check in which environment we are currently working in


console.log(app.get('env'));

or

console.log(process.env) //process is a global core module in node js

In terminal if you want to set your env you can do this

> NODE_ENV=development npm run server.js

once the development is completed change it to production.. But if there are several env variables then its not a  good idea to set them in terminal so instead of doing this make a configuration file called config.env

**** Connecting .env file

npm install dotenv

// In server.js
const dotenv = require('dotenv');
dotenv.config({path: './config.env'})
define these two line on very top of your file

console.log(process.env); // To confirm the connection of env variables


***************ES lint

ES lint is basically a program which continuously scans our code for errors and bad practices. We use Prittier but we will also configure it with our es lint to highlight the errors. ES lint is for improve the quality of code.

Install ES lint and prettier extension in vscode

then 
$ npm install eslint prettier eslint-config-prettier eslint-plugin-prettier eslint-config-airbnb eslint-plugin-node eslint-plugin-import eslint-plugin-jsx-a11y eslint-plugin-react --save-dev



// In .eslintrc.json
{
  "extends": ["airbnb", "prettier", "plugin:node/recommended"],
  "plugins": ["prettier"],
  "rules": {
    "prettier/prettier": [
      "error",
      {
        "endOfLine": "auto"
      }
    ],
    "spaced-comment": "off",
    "no-console": "warn",
    "consistent-return": "off",
    "func-names": "off",
    "object-shorthand": "off",
    "no-process-exit": "off",
    "no-param-reassign": "off",
    "no-return-await": "off",
    "no-underscore-dangle": "off",
    "class-methods-use-this": "off",
    "prefer-destructuring": ["error", { "object": true, "array": false }],
    "no-unused-vars": ["error", { "argsIgnorePattern": "req|res|next|val" }]
  }
}


// In .prettierrc

{
  "singleQuote": true
}



************************MongoDB
its a NoSql database.
In Mongo DB each database can have more than once collection. 
Collections are like tables. And each collection contains document. 
By documents you can say Rows. Each row would be for post, user, reviews etc.
The good thing is that Document (rows) have JOSN like format but it is called BSON (Here all values will have some data type such as boolean, string, etc.)


Document based: MongoDB is a document based database it stores data in the form of document instead of rows as in traditional databases.
Scalabilty: Very easy to distribute data across multiple machine as your user and amount of data grows.
Flexible: No document data Schema required so each document can have different number and types of fields.

In relational data bases the data is always normalise.

In BSON:

1. maximum size of each document is 16MB
2. Each document has a unique id which act as a primary key for each document.


**********Installing mongoDB

Go to mongoDB official website --> Products --> MongoDB Community Server --> Download

Dont forget to create data and db folder inside C

Now arfter installing  the setup go to c drive --> program files --> mongoDB--> server --> 7.0 --> bin 

and copy its path 

now go to environemental variables of your windows and add this path there.
After adding this 

open your powershell or cmd

**********How to run local MongoDB server from cmd or powershell and how to connet it with DB
open your powershell or cmd

> mongod.exe

and now open another terminal and run > mongos.exe

************Connecting to a local database with cmd or powershell
open cmd and run

> mongosh.exe

> use databaseName
// here use commnand is used to switched b/w db if db doesnt exist it will create that automatically

Since we know that in mongoDB every document (row) is inside the a collection (table) so this means we first have to create collections then documents

** Adding data into database

>db.tours.insertOne({name:"The Forest Hiker", price: 297, rating: 4.7})
syntax: db.collectionName.function(data in BSON format)

insertOne is used to insert one document and insertMany is used to insert more than one documents

*** Checking the created collection
>db.tours.find()

** checking all databases we created
> Show dbs

*** checking all collections

> show collections

******Quiting the mongoshell

> quit()


************Inserting multiple documents in single collection
>  db.tours.insertMany([{name: "The Sea Explorer", price: 497, rating: 4.8}, {name: "The Snow Adventure", price:997, rating: 4.9, difficulty: "easy"}])

This is how you enter multiple document in a single collection. 
**NOTE**: Always remember we are entering more than one document in the form of arrays. and Mongo DB understand double quote only.

*************Finding a specific object or document**************
> db.tours.find({name: "The Snow Adventure"})

MongoDb is case sensitive so incase of wrong spelling or case sensitive mistake it will show nothing.

> db.tours.find({price: {$lt:500}})

here we are finding objects having price less than 500. Here $ sign means mongo operator. You write your expressions in curly brackets {}
and same case goes for greater than operator you use {$gt:500} 

lt = less than
gt = greater than
lte= less than equal
gte = greater than equal


*********Using AND Operator
> db.tours.find({ price: {$lt:500}, rating: {$gte:4.8} })

Here comman is acting as AND operator. It is by default.

************Using OR operator

> db.tours.find({$or: [{price:{$lt:500} },{rating: {gte:4.8} }] })
 This is how you find objects in mongoDB using OR operator.

>db.tours.find({$or: [{price:997 },{rating: {gte:800} }] }, {name:1})

Here {name:1} means name true. Means The output will include only name field.

**********Updating the data/document

> db.tours.updateOne({name: "The Snow Adventure"}, {$set: {price: 597} })

syntax:  db.tours.updateOne(filter Object, {$set: {property:value} })

here filter object means the data with the help of you will select your object.


*********Adding new field in the existing document using updatingMany

> db.tours.updateMany({price: {$gt:500},rating:{$gte:4.8}}, {$set: {premium: true}})

by using this {price: {$gt:500},rating:{$gte:4.8}} we are selecting multple objects in between the given range and then the second argument is here to set the value.

**************Delete Data

>db.tours.deleteOne({price:497})

>db.tours.deleteMany({rating:{$lt:4.8}}) 
This is for deleting all objects have rating less than 4.8

>db.tours.deleteMany({})


************Using MongoDB Compass

Simply open your MongoDB compass and click on new connection and wihtout filling anything click on connect button
make sure your Mongod.exe server is running on backend in cmd or powershell.

you can use above queries in mongoDB compass filter field

*********Hosting a database

While developing apps we do not use actual local data bases for our use instead we host our remote database on as service called Atlas. Which is owned my the same company who own MongoDB.
Cluster is basically like an instance of our database.

Simply go to mongo login and login your account create a new project and add user and add IP address

Now to connect you will get a connection URL like mongodb+srv://<USERNAME>:<PASSWORD>@clustername.mongodb.net/test



****************Getting access to remote Database using CMD
To access a MongoDB Atlas database from your Windows Command Prompt, you can use the `mongosh` utility, which is the MongoDB Shell. Here are the steps to connect to your remote MongoDB Atlas database:

1. Open your Windows Command Prompt:
   - Press `Win + R`, type `cmd`, and press Enter.

2. Navigate to the directory where `mongosh.exe` is located if it's not in your system's PATH:
   - Use the `cd` command to change the directory. For example, if `mongosh.exe` is in the "C:\Program Files\MongoDB\Tools\100\bin" directory, you can navigate to it using:
     ```
     cd "C:\Program Files\MongoDB\Tools\100\bin"
     ```

3. Now, you can connect to your MongoDB Atlas cluster using the following command:
   ```
   mongosh "mongodb+srv://<USERNAME>:<PASSWORD>@clustername.mongodb.net/test" --authenticationDatabase admin
   ```
   Replace `<USERNAME>` and `<PASSWORD>` with your MongoDB Atlas cluster username and password. Also, replace `clustername` with the name of your MongoDB Atlas cluster.

4. Press Enter, and `mongosh` will connect to your MongoDB Atlas cluster.

For example, if your MongoDB Atlas username is "myuser," your password is "mypassword," and your cluster name is "mycluster," the command would look like this:

```shell
mongosh "mongodb+srv://myuser:mypassword@mycluster.mongodb.net/test" --authenticationDatabase admin
```

After running this command, you should be connected to your MongoDB Atlas cluster and can start interacting with your remote database.

OR simply get the link of your database that you put into your mongoDB compass

mongosh "mongodb+srv://username:<Password>@cluster0.vsioz83.mongodb.net/<DatabaseName>?retryWrites=true&w=majority"


***************In Summary of MongoDB

There are two servers one is local that is on your computer and other one is remote that is on Atlas
To get access to your local server you simply have to run mongod.exe in your terminal (remember you have added the path of bin directory of mongoDB in your windows environmental variables)
After running this mongod.exe you have created a local server in your PC. To get access to this locally created Database you simply have to open another terminal and run mongosh.exe
Congrats. You are done!


For Remote database: You first have to host your database to remote server that is Atlas. Simple go to mongoDB Atlas login and create database there and get its URL
Now open your terminal and run mongosh "mongodb+srv://<USERNAME>:<PASSWORD>@clustername.mongodb.net/test" 
Congrats, You are done!

************How to connect your database with your app

Connecting local database:
you can use the below URL for connecting to the local database


mongodb://localhost:27017/natours

syntax:
mongodb://localhost:27017/DatabaseName


Connecting to hosted database:

mongodb+srv://rabahalishah:<PASSWORD>@cluster0.vsioz83.mongodb.net/DATABASENAME?retryWrites=true&w=majority

For talking to the database there are several drivers we are gonna use Mongoose.

npm install mongoose

********************Using mongoose driver to connect with hosted database

// In config.env file:
NODE_ENV=development
PORT=3000
DATABASE_PASSWORD=123456
DATABASE=mongodb+srv://rabahalishah:<PASSWORD>@cluster0.vsioz83.mongodb.net/natours?retryWrites=true&w=majority
DATABASE_LOCAL=mongodb://localhost:27017/natours


// In server.js
const DB = process.env.DATABASE.replace(
  '<PASSWORD>',
  process.env.DATABASE_PASSWORD,
);

// here simply getting the url from env file

mongoose
  .connect(DB, {
    useNewUrlParser: true,
    useCreateIndex: true,
    useFindAndModify: false,
  })
  .then((con) => {
    console.log(con.connections);
    console.log('Database Connected Successfully');
  });


// here mongoose.connect returns a promise which have access to connection object which contains the information about our connection


*************What is mongoose

Before getting started lets discuss what is mongoose
Mongoose is ODM (Object data modelling) library for mongoDB and Node.js. It is build on higher level of abstraction. As express is layer on nodeJs similarly mongoose is a layer on MongoDB.  There are several mongoDB driver but we prefer mongoose because of its flexibility and easier development experience. 

Features of mongoose: 
1. Shemas to model data and relationships.
2. Easy Data validation.
3. Simple query API
4. Middlerwares etc.

Mongoose Schema: Where we model our data, by describing the structure of the data, default values and validations.
Mongoose model: its a wrapper for the schema, providing an interface to the database for CRUD operations.



***********Creating simple schema and model

we will creating our schema and model in sevre.js but we wil shift it in the other directory later.

This is how we create schemas in mongoDB using mongoose:


const tourSchema = new mongoose.Schema({
  name: {
    type: String,
    required: [true, 'A tour must have a name'],
    unique: true,
  },
  rating: {
    type: Number,
    default: 4.5,
  },
  price: {
    type: Number,
    required: [true, 'A tour must have a price'],
  },
});



// Here required option is a validator and the array in required: [true, 'A tour must have a name'], here the second argument is the message which is gonna appear in case the user do not enter the name of tour


NOTE: One thing that you must notice here is that in case the use is sending the information which is not in our schemas then in this case we that data will be simply ignored and only that data will be allowed to go into the database which is included in our schemas.
********Now creating a model out of above schema

const Tour = mongoose.model('Tour', tourSchema);

This is how we create model of our schema. Remember the convention as the name of the model starts with captital letter. Model is nothing its simple our collection.

// Here 'Tour' is the name of our collection but in database it will save as 'tours' (plural) instead of 'Tour'. So don't be confused with it.


***********Creating documents and testing the model
One thing you have to remember is that working with mongoDB model is same as working with javascript classes. For example we create instances of the object to create a new object.
same case will go here as we have created our Tour Model This will act as object now to create a new document we will create its instance using "new" as we do in Classes

so 

const testTour = new Tour({
  name: 'The Forest Hiker',
  rating: 4.7,
  price: 497,
})
  .save()
  .then((doc) => {
    console.log('doc: ', doc);
  })
  .catch((err) => {
    console.log('Error', err);
  });


// here testTour is our new instance of Tour model so this means we can apply all methods on it which we can apply on Tour Model. Thats why we can use save() method to save it.
since save() method returns a promise so we are handling that too.

Btw there is another way of creating the document.

Tour.create({
  name: 'The Forest Hiker',
  rating: 4.7,
  price: 497,
}).then(doc=>{
  console.log(doc)
})

The second one is the easy one


*************Introduction to Backend Architecture, MVC types of logic and more


MVC (Model view controller) Architecture.

Model: This layer concerned with the Application data and business logic
Controller: This layer is responsible for handling user http requests, sending responses and much more.
View: This layer is used when we are doing SSR or for presentational logic.

Application logic vs business logic:

Remember its always impossible to completely separate the business and application logic as these logic overlaps to some extend. We try our best to keep the application logic in our controller and business logic in our model 

Application logic:
Its a code which is more concerned with the working of application such as dealing with request-response cycle. And more technical stuff.
Its also works as the bridge between model and view layer.

Business logic:
Its a code which is more concerned with the business things to solve the problem which is set out to solve such as showing and selling tours in our case.
This logic is directly related to our business rules and needs.
For example:
1. creating new tours in database
2. checking if the user is valid
3. validating user input data
4. Ensuring only users who bought a tour can review it.


****************Creating a new document with mongoose in via post request
exports.createTour = async (req, res) => {
  try {
    console.log('Req.body', req.body);
    const newTour = await Tour.create(req.body);
    console.log('New tour', newTour);

    res.status(200).json({
      status: 'success',
      data: {
        tour: newTour,
      },
    });
  } catch (err) {
    res.status(400).json({
      status: 'fail',
      message: 'Invalid data sent!',
    });
  }
};



******************Reading data from database with mongoose

exports.getAllTours = async (req, res) => {
  try {
    const tours = await Tour.find();

    res.status(200).json({
      status: 'success',
      results: tours.length,
      data: {
        tours: tours,
      },
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};

exports.getTour = async (req, res) => {
  try {
    const tour = await Tour.findById(req.params.id);
    // Tour.findOne({_id: req.params.id})
    res.status(200).json({
      status: 'success',
      data: {
        tour: tour,
      },
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};


NOTE: we are entering the id of the user in the url from the postman
GET 127.0.0.1:3000/api/v1/tours/652263f6f27ee20d54b43c82



***************Updating the data with mongoose

exports.updateTour = async (req, res) => {
  try {
    const tour = await Tour.findByIdAndUpdate(req.params.id, req.body, {
      new: true,
      runValidators: true,
    });
    res.status(200).json({
      status: 'success',
      data: {
        tour: tour,
      },
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};


POSTMAN:  PATCH  127.0.0.1:3000/api/v1/tours/652263f6f27ee20d54b43c82


NOTE: const tour = await Tour.findByIdAndUpdate(req.params.id, req.body, {
      new: true,
      runValidators: true,
    });

findByIdAndUpdate() this method take two arguments one id and other is the changes that we want to change, and third is the option object where we can define some options such as
here new: true means this method will return a new object and runValidators: true means after updating the object the validators must be run to check the validation once again.

IMPORTANT: The body we have sent from the postman was{"price":500} Since the HTTP method  was PATCH instead of PUT thats this method only changed the price and returned the new object with new price. Whereas if you have used PUT method here then by sending the body like { "price":500 } then the put method was completely going to replace the existing object with {"price":500} and we will get {"price":500} only



**************Deleting data using mongoose

exports.deleteTour = async (req, res) => {
  try {
    await Tour.findByIdAndRemove(req.params.id);
    res.status(204).json({
      status: 'success',
      data: null,
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};

// here its a standard practice that we do not send back the promise in case of deleting any object


*************Modeling our Tour Data
const tourSchema = new mongoose.Schema({
  name: {
    type: String,
    required: [true, 'A tour must have a name'],
    unique: true,
    trim: true,
  },
  duration: {
    type: Number,
    required: [true, 'A tour must have a duration'],
  },
  maxGroupSize: {
    type: Number,
    required: [true, 'A tour must have a group size'],
  },
  difficulty: {
    type: String,
    required: [true, 'A tour must have a difficulty'],
  },
  ratingsAverage: {
    type: Number,
    default: 4.5,
  },
  ratingsQuantity: {
    type: Number,
    default: 0,
  },
  price: {
    type: Number,
    required: [true, 'A tour must have a price'],
  },
  priceDiscount: Number,
  summary: {
    type: String,
    trim: true, 
    required: [true, 'A tour must have a summary'],
  },
  description: {
    type: String,
    trim: true,
  },
  imageCover: {
    type: String,
    required: [true, 'A tour must have a cover Image'],
  },
  images: [String],
  createdAt: {
    type: Date,
    default: Date.now(),
  },
  startDates: [Date],
});


//Here Trim will remove spaces in the start and end of the string


Our input body while making HTTP POST Request
{
    "name": "The Snow Adventurer",
    "duration": 4,
    "maxGroupSize": 10,
    "difficulty": "difficult",
    "ratingsAverage": 4.5,
    "ratingsQuantity": 13,
    "price": 997,
    "summary": "Exciting adventure in the snow with snowboarding and skiing",
    "description": "Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua, ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum!\nDolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur, exercitation ullamco laboris nisi ut aliquip. Lorem ipsum dolor sit amet, consectetur adipisicing elit!",
    "imageCover": "tour-3-cover.jpg",
    "images": ["tour-3-1.jpg", "tour-3-2.jpg", "tour-3-3.jpg"],
    "startDates": ["2022-01-05,10:00", "2022-02-12,10:00", "2023-01-06,10:00"]
  }




****************Importing data from file to MongoDB database
NOTE: This script is totally independent of the project. This is here to give you an extra knowledge. How you can transfer you data from you .json file to mongoDB database with the help of mongoose.

// In import-dev-data.js

const fs = require('fs');
const mongoose = require('mongoose');
const dotenv = require('dotenv');

const Tour = require('./../../models/tourmodel'); // Importing out model/collection

dotenv.config({ path: './config.env' });

const DB = process.env.DATABASE.replace(
  '<PASSWORD>',
  process.env.DATABASE_PASSWORD,
);
mongoose
  .connect(DB, {
    useNewUrlParser: true,
    useCreateIndex: true,
    useFindAndModify: false,
    useUnifiedTopology: true,
  })
  // eslint-disable-next-line no-console
  .then(() => console.log('Database Connected Successfully'));

// Readung json file
const tours = JSON.parse(
  fs.readFileSync(`${__dirname}/tours-simple.json`, 'utf-8'),
);
/* parse() JSON parsing is the process of converting a JSON object in text format to a Javascript object
 that can be used inside a program*/

// importing data into DB
const importData = async () => {
  try {
    await Tour.create(tours);
    console.log('Data successfully loaded!');
  } catch (err) {
    console.log(err);
  }
  process.exit();
};

// Deleting already present data in database
const deleteData = async () => {
  try {
    await Tour.deleteMany(); //we will pass nothing so it will delete all the data
    console.log('All previous data deleted successfully');
  } catch (err) {
    console.log(err);
  }
  process.exit();
};

if (process.argv[2] === '--import') {
  importData();
} else if (process.argv[2] === '--delete') {
  deleteData();
}
console.log(process.argv);


//**Explanation of the script
In this file we are simply importing our data from the .json file using fs module and converting it into the Javascript obj using JSON.parse. After that  we are connecting our script to our Database. Simply using create and delete function of mongoose to import new data and delete previous data respectively.


Here the new thing we have to noticed that is process.argv. Yes you are guessing right! we had used this in python. This method is used to access the input from the command line
for example:

node filename.js blah_blah

then on consoloing the process.argv we will get

[
  'C:\\Users\\muham\\AppData\\Roaming\\nvm\\v20.4.0\\node.exe',
  'C:\\Doctor\\Work\\Playground\\NodeJS by Jonas\\Natrous_API\\dev-data\\data\\import-dev-data.js',
  'blah_blah'
]

Using this feature we can create some logic


*************Making the API Better filtering
Making the sorting better for getAllTour Route
We are doing it so as user can apply queries to our API

// In tourController.js

exports.getAllTours = async (req, res) => {
  try {
    const queryObj = { ...req.query };
    const excludedFields = ['page', 'sort', 'limit', 'fields'];
    excludedFields.forEach((el) => delete queryObj[el]); // excluding some keywords
    console.log('req.query: ', req.query);
    console.log('queryObj: ', queryObj);
    const query = await Tour.find(queryObj);
    // here we are passing the queryObj
    const tours = await query;




    res.status(200).json({
      status: 'success',
      results: tours.length,
      data: {
        tours: tours,
      },
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};

NOTE: here queryObj is a hard copy not a shallow copy. Means if we do any changes in the queryObj object it will not
effect the req.query Obj This is the most important trick to create a hard copy in JS.
If we directly assign as const queryObj = req.query then as we know objects are references in JS not the actual object.
So in order to create a hard or deep copy we use destruturing instead of directly assigning to it a variable.

Also note that we do not want our user to go to the pages using query string as "127.0.0.1:3000/api/v1/tours?duration=5&difficulty=easy&page=2" so in order to exclude some key words that we do not want our API should have we are excluding it using loop over them.

**********Making API better filtering advance

here in this section we will deal with some more complex queries such as greater than, less than, greater than equal and less than equal.

As we all know in mongoDB we do query to find such greater or less is this way
// db.tours.find({duration: {$gte:5}})

and in url we can do the same in this way:
127.0.0.1:3000/api/v1/tours?duration[gte]=5

In square brackets we write [operators]

so in our JS code we have to write a logic to deal with gte, lte, gt and lt operators to more advance our filtering query.

127.0.0.1:3000/api/v1/tours?duration[gte]=5
whenever the user hit the url the above query strintg the output of req.query object would be:

{duration: {gte:5}}

the only thing which is missing here is the dollar sign. So lets add that

    const queryObj = { ...req.query }; //creating deep copy

    const excludedFields = ['page', 'sort', 'limit', 'fields'];
    excludedFields.forEach((el) => delete queryObj[el]); // deleting the unwanted keywords
    console.log('req.query: ', req.query);
    console.log('queryObj: ', queryObj);

    // here we are doing some advance filtering
    let queryStr = JSON.stringify(queryObj);
    queryStr = queryStr.replace(/\b(gte|gt|lt|lte)\b/g, (match) => `$${match}`); 
    console.log('queryStr: ', JSON.parse(queryStr));

    const query = await Tour.find(JSON.parse(queryStr));
    // here we are passing the queryObj which is a deep copy

    const tours = await query;

// here we are using regular expression to match the words
the logic we are using is simple we are simple replacing the word with the same word but having a dollar $ sign with it.

JSON.stringify and JSON.parse both are work opposite to eachother.


**************Making API better Sorting 

If user hit "127.0.0.1:3000/api/v1/tours?duration[gte]=5&difficulty=easy&sort=price"
this URL will not work as we have excluded the word sort from the url so now lets add it

using this req.query.sort we can get the value of sort which the user has passed in the url

    let query = Tour.find(JSON.parse(queryStr));
    Tour.find() method returns a query object or data which this method has found.

    // Sorting
       if (req.query.sort) {
      const sortBy = req.query.sort.split(',').join(' ');
      query = query.sort(sortBy);
    } else {
      query = query.sort('-createdAt');
      // This is for default sorting when user does not specify any sorting
    }

NOTE: We are not over writting the above queries. We are making a chain or you can say we are passing our URL through different layers so that It can hadle all cases



*******************Making API better limiting field
It is always a good practice to receive as little data as possible from the user so that we can reduce the bandwith. 

127.0.0.1:3000/api/v1/tours?duration[gte]=5&fields=name,price,duration

here the user is specifying only specific fields

we can deal with this query in the similar way as we did in sorting

   if (req.query.fields) {
        const fields = req.query.fields.split(',').join(' ');
        query = query.select(fields);
      } else {
        query = query.select('-__v');
      }

// here  you have noticed that there is a negative sign with __v field. In this case __v is field created by the mongoDB in the Database automatically we do not want our user to see this unnecessary info so using select method -ve means exclude or unselect.

NOTE: In any case you want any specific info which is in your schema and you want to hide it from access you can simply use select:false property in the schema as:

  createdAt: {
    type: Date,
    default: Date.now(),
    select: false,
  }

now the createdAt field will not be displayed


****************Making API Better pagination
The amount of data per page we want to limit
  // Pagination
    const page = req.query.page * 1 || 1; //multiplying by 1 to convert string into a number
    const limit = req.query.limit * 1 || 100;
    const skip = (page - 1) * limit;
    query = query.skip(skip).limit(limit);
    // Below we are checking that a page does exists or not
    if (req.query.page) {
      const numTour = await Tour.countDocuments();
      if (skip >= numTour) throw new Error('This page does not exists');
    }

127.0.0.1:3000/api/v1/tours?duration[gte]=5&page=1&limit=3

********Making API better Aliasing
So let assume that the user wants to get the top 5 cheap tour then the user must have to enter the query like below:
/limit=5&sort=-ratingsAverage,price

so in order to make it simple and more easy to write we will use alias for top 5 cheap tours

// In tourRouter.js
router
  .route('/top-5-cheap')
  .get(tourController.aliasTopTours, tourController.getAllTours);

created a new route which runs a middleware called aliasTopTours

// In tourController.js
// pre-filling the query string
exports.aliasTopTours = (req, res, next) => {
  req.query.limit = '5';
  req.query.sort = '-ratingsAverage,price';
  req.query.fields = 'name,price,ratingsAverage,summary,difficulty';
  next();
};


Here we are prefilling our query so that our link will look like this 

127.0.0.1:3000/api/v1/tours/top-5-cheap

behind the scenes our query will be 

127.0.0.1:3000/api/v1/tours/limit=5&sort=-ratingsAverage,price&fields=name,price,ratingsAverage,summary,difficulty


*************Summary
exports.getAllTours = async (req, res) => {
  try {
     // here queryObj is a hard copy not a shallow copy. Means if we do any changes in the queryObj object it will not
     //effect the req.query Obj This is the most important trick to create a hard copy in JS.
     // If we directly assign as const queryObj = req.query then as we know objects are references in JS not the actual object.
     // So in order to create a hard or deep copy we use destruturing instead of directly assigning to it a variable.

    const queryObj = { ...req.query };
    const excludedFields = ['page', 'sort', 'limit', 'fields'];
     excludedFields.forEach((el) => delete queryObj[el]);
     console.log('req.query: ', req.query);

     // Doing some advance filtering
     let queryStr = JSON.stringify(queryObj);
     // here we are passing the queryObj which is a deep copy
     queryStr = queryStr.replace(/\b(gte|gt|lt|lte)\b/g, (match) => `$${match}`);

     let query = Tour.find(JSON.parse(queryStr));

     Sorting

    if (req.query.sort) {
      const sortBy = req.query.sort.split(',').join(' ');
      query = query.sort(sortBy);
    } else {
      query = query.sort('-createdAt');
      // This is for default sorting when user does not specify any sorting

      if (req.query.fields) {
        const fields = req.query.fields.split(',').join(' ');
        query = query.select(fields);
      } else {
        query = query.select('-__v');
      }
    }
    // Pagination
    const page = req.query.page * 1 || 1; //multiplying by 1 to convert string into a number
    const limit = req.query.limit * 1 || 100;
    const skip = (page - 1) * limit;
    query = query.skip(skip).limit(limit);
    // Below we are checking that a page does exists or not
    if (req.query.page) {
      const numTour = await Tour.countDocuments();
      if (skip >= numTour) throw new Error('This page does not exists');
    }
    const tours = await query;

    res.status(200).json({
      status: 'success',
      results: tours.length,
      data: {
        tours: tours,
      },
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};


********Refractoring the code using classes

Now its time to make this features code in the separate folder so that we could use it in other code as well

make a directory namely "utils" and inside that folder create a file called "apiFeatures.js"

// In apiFeatures.js

class APIFeatures {
  constructor(query, queryString) {
    this.query = query; // query is the data present in Tour model i.e Tour.find()
    this.queryString = queryString; //queryString is a query which coming from express
  }

  filter() {
    // here this.queryString is equal to req.query
    // here queryObj is a hard copy not a shallow copy. Means if we do any changes in the queryObj object it will not
    //effect the req.query Obj This is the most important trick to create a hard copy in JS.
    // If we directly assign as const queryObj = req.query then as we know objects are references in JS not the actual object.
    // So in order to create a hard or deep copy we use destruturing instead of directly assigning to it a variable.

    const queryObj = { ...this.queryString };
    const excludedFields = ['page', 'sort', 'limit', 'fields'];
    excludedFields.forEach((el) => delete queryObj[el]);
    // console.log('req.query: ', req.query);

    // Doing some advance filtering
    let queryStr = JSON.stringify(queryObj);
    // here we are passing the queryObj which is a deep copy
    queryStr = queryStr.replace(/\b(gte|gt|lt|lte)\b/g, (match) => `$${match}`);

    this.query = this.query.find(JSON.parse(queryStr));

    return this;
  }

  sort() {
    if (this.queryString.sort) {
      const sortBy = this.queryString.sort.split(',').join(' ');
      this.query = this.query.sort(sortBy);
    } else {
      this.query = this.query.sort('-createdAt');
      // This is for default sorting when user does not specify any sorting
    }
    return this;
  }

  limitFields() {
    if (this.queryString.fields) {
      const fields = this.queryString.fields.split(',').join(' ');
      this.query = this.query.select(fields);
    } else {
      this.query = this.query.select('-__v');
    }
    return this;
  }

  paginate() {
    const page = this.queryString.page * 1 || 1; //multiplying by 1 to convert string into a number
    const limit = this.queryString.limit * 1 || 100;
    const skip = (page - 1) * limit;
    this.query = this.query.skip(skip).limit(limit);

    return this;
  }
}

module.exports = APIFeatures;


we have replaced req.query with this.queryString and query with this.query
1. here query is the data present in Tour model i.e Tour.find()
2. queryString is a query which coming from express i.e req.query


// In tourController.js

const Tour = require('./../models/tourmodel');

 const features = new APIFeatures(Tour.find(), req.query)
      .filter()
      .sort()
      .limitFields()
      .paginate();
    const tours = await features.query;

// Here we are simply creating a new instance of APIFeature class and applying methods on it which we have created in original APIFeature class.

*************Aggregartion pipeline matching and grouping

The Idea is that all our document will pass through a collection of processes such as calculating avgs etc.
we will make this pipeline.


Aggregation pipeline is basically a mongoDB feature which we will access with the help of Mongoose.

The data will pass through the multiple stages and that will transform the data into an aggregated result.

// In toursController.js
exports.getTourStats = async (req, res) => {
  try {
    const stats = await Tour.aggregate([
      {
        $match: { ratingsAverage: { $gte: 4.5 } },
      },
      {
        $group: {
          _id: { $toUpper: '$difficulty' },
          // _id: '$ratingsAverage',
          numTours: { $sum: 1 },
          numRating: { $sum: '$ratingsQuantity' },
          avgRating: { $avg: '$ratingsAverage' },
          avgPrice: { $avg: '$price' }, // here price is the name of the field
          minPrice: { $min: '$price' },
          maxPrice: { $max: '$price' },
        },
      },
      {
        $sort: {
          avgPrice: 1, // In sort object only those fields name will work which we have specified above in the group stage.
        },
      },
 //     {
 //       $match: { _id: { $ne: 'EASY' } },
 //     },
    ]);

    res.status(200).json({
      status: 'success',
      data: { stats },
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};

// Here each object is stage. In this case we have made three stages:
1. In first stage we are matching or you can say selecting
2. In second stage we are grouping our data in terms of difficulty,
3. we are sorting our data

// In tourRoutes.js

router.route('/tour-stats').get(tourController.getTourStats);


// here we have created a separate route to get all the stats related to our tours.



*********Solving a business problem using Aggregation Pipeline:
The problem is to get the busiest month for natours company

// In tourController.js

exports.getMonthlyPlane = async (req, res) => {
  try {
    const year = req.params.year * 1;


    const plan = await Tour.aggregate([
      {
        $unwind: '$startDates',
      },
      {
        $match: {
          startDates: {
            $gte: new Date(`${year}-01-2021`),
            $lte: new Date(`${year}-12-31`),
          },
        },
      },
      {
        $group: {
          _id: { $month: '$startDates' },
          numTourStarts: { $sum: 1 },
          tours: { $push: '$name' },
        },
      },
      { $addFields: { month: '$_id' } },
      {
        $project: {
          // project is used for hiding a field
          _id: 0,
        },
      },
      {
        $sort: { numTourStarts: -1 }, //-1 for descending
      },
      {
        $limit: 6, //This is just limiting our number of output documents
      },
    ]);
    res.status(200).json({
      status: 'success',
      data: {
        plan,
      },
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};


// This is the aggregation pipe line. Here, "$unwind" Deconstructs an array field from the input documents to output a document for each element. Each output document is the input document with the value of the array field replaced by the element.


// In tourRoutes.js
router.route('/monthly-plan/:year').get(tourController.getMonthlyPlane);

// The input url: 127.0.0.1:3000/api/v1/tours/monthly-plan/2021

ouput: 
{
    "status": "success",
    "data": {
        "plan": [
            {
                "numTourStarts": 3,
                "tours": [
                    "The Forest Hiker",
                    "The Sea Explorer",
                    "The Sports Lover"
                ],
                "month": 7
            },
            {
                "numTourStarts": 2,
                "tours": [
                    "The Sea Explorer",
                    "The Park Camper"
                ],
                "month": 8
            },
            {
                "numTourStarts": 2,
                "tours": [
                    "The Forest Hiker",
                    "The Star Gazer"
                ],
                "month": 10
            },
            {
                "numTourStarts": 2,
                "tours": [
                    "The Sea Explorer",
                    "The City Wanderer"
                ],
                "month": 6
            },
            {
                "numTourStarts": 2,
                "tours": [
                    "The Forest Hiker",
                    "The Wine Taster"
                ],
                "month": 4
            },
            {
                "numTourStarts": 2,
                "tours": [
                    "The City Wanderer",
                    "The Star Gazer"
                ],
                "month": 3
            }
        ]
    }
}


**************Virtual properties

// In tourModel.js

const tourSchema = new mongoose.Schema(
  {
   .....Our Schemas
  },
  {
    toJSON: { virtuals: true },
    toObject: { virtuals: false },
  },
);
// Here above in schema options we have set to show our created virtuals to true in case of JSON and to hide them in case of object.

tourSchema.virtual('durationWeek').get(function () {
  return this.duration / 7;
});

// here the virtual is a category which we specify when we do not want to store the information in the database but just want to
// show. As it doesn't make sense to store the same info with different units. Now from schema options we can manage this virtual property. REMEMBER: we cannot use queries on virtuals as they are actually not a part of database.

*************Document Middlerware

In monsgoose we can create middleware which can run before and after an event. In mongoose they are often called pre or post Hooks.

There are four types of middleware in mongoose
1. Document
2. Query
3. Aggregate
4. Model

**Document Middleware
Just like the virtual property we will define our document middle ware on our schema in model.js file

// In model.js

// DOCUMENT MIDDLEWARE: runs before .save() and .create()
// This middleware will not work for .insertMany()
tourSchema.pre('save', function (next) {
  this.slug = slugify(this.name, { lower: true });
  next();
});

tourSchema.pre('save', function (next) {
  console.log('will save document');
  next();
});

// DOCUMENT MIDDLEWARE: runs after the .save() and .create()
tourSchema.post('save', function (doc, next) {
  console.log('doc: ', doc);
  next();
});

here this keyword is pointing towards the current document that is going to be saved
NOTE: Dont forget to add slug : String in schemas


**Query Middleware

// IN model.js

//QUERY MIDDLEWARE

// tourSchema.pre('find', function (next) {
//   this.find({ secretTour: { $ne: true } });
//   next();
// });
// This query will not work for findOne, findOneAndUpdate etc.
//To make it work for that we are using regular expressions
tourSchema.pre(/^find/, function (next) {
  this.find({ secretTour: { $ne: true } });

  this.start = Date.now();
  next();
});
// here this experssion /^find/ means that any query starting with find

tourSchema.post(/^find/, function (docs, next) {
  console.log(docs);
  console.log(`The Query Took ${(Date.now() - this.start) / 1000} seconds`);

  next();
});


NOTE: You may have noticed that all middlewares look same but the difference between the query and document middleware is that document works with save and query works with find etc.

post hook in mongoose also have access to document object.

in case of pre hook query middleware the this keyword is pointing towared the current query object on which we can apply all methods

Dont forget to add the below in you schemas:
  secretTour: {
      type: Boolean,
      default: false,
    }, 



**AGGREATE Middleware

//AGGREGATION MIDDLEWARE
tourSchema.pre('aggregate', function (next) {
  this.pipeline().unshift({ $match: { secretTour: { $ne: true } } });
  console.log('aggregation middleware pipeline: ', this.pipeline());

  next();
});

Here unshift is a javascript method which is used to add the elements at the beginning of the array similarly we have shift method which is used to add elements at the end of the array



**********Data Validation in mongoose
Validation simply means that whether the entered data is in right format or not.
There is another concept called sanitization. Which simply means whether the entered data is clean or not.
It is a GOLDEN standard in backend development that never ever receive data from backend as it is.

We have added some built in validators in our Model schemas which are given below:
const tourSchema = new mongoose.Schema(
  {
    name: {
      type: String,
      required: [true, 'A tour must have a name'],
      unique: true,
      trim: true,
      maxlength: [40, 'A tour must have less than or equal to 40 characters'],
      minlength: [
        10,
        'A tour name must have greater or equal than 10 character',
      ],
    },
    slug: String,
    duration: {
      type: Number,
      required: [true, 'A tour must have a duration'],
    },
    maxGroupSize: {
      type: Number,
      required: [true, 'A tour must have a group size'],
    },
    difficulty: {
      type: String,
      required: [true, 'A tour must have a difficulty'],
      enum: {
        values: ['easy', 'medium', 'difficult'],
        message: 'Difficulty can either be: easy, medium or difficult',
      },
      
    },
    ratingsAverage: {
      type: Number,
      default: 4.5,
      minlength: [1, 'Rating must be above 1.0'],
      maxlength: [5, 'Rating must be below 5.0'],
    },
    ratingsQuantity: {
      type: Number,
      default: 0,
    },
    price: {
      type: Number,
      required: [true, 'A tour must have a price'],
    },
    priceDiscount: Number,
    summary: {
      type: String,
      trim: true, //Trim will remove spaces in the start and end of the string
      required: [true, 'A tour must have a summary'],
    },
    description: {
      type: String,
      trim: true,
    },
    imageCover: {
      type: String,
      required: [true, 'A tour must have a cover Image'],
    },
    images: [String],
    createdAt: {
      type: Date,
      default: Date.now(),
      select: false,
    },
    startDates: [Date],
    secretTour: {
      type: Boolean,
      default: false,
    },
  },
  {
    toJSON: { virtuals: true },
    toObject: { virtuals: false },
  },
);

//here enum is only for strings which are allowed

*************Custom validators
Sometimes builtin validators are not enough to meet our requirements. Custom validators are here to fill the gap.
Custom validators are nothing just a simple function which returns either true or false. On the basis of which the input is accepted

 price: {
      type: Number,
      required: [true, 'A tour must have a price'],
    },
    priceDiscount: {
      type: Number,
      validate: {
        validator: function (val) {
          // here this keyword is pointing toward the value entered by the user on creating NEW document
          return val < this.price;
        },
        message: 'Discount price ({VALUE}) must be less than the actual price',
      },
    },

// This is how we define a custom validator.

//There are several libraries for making custom validators we are gonna use "validator"

npm install validator

  name: {
      type: String,
      required: [true, 'A tour must have a name'],
      unique: true,
      trim: true,
      maxlength: [40, 'A tour must have less than or equal to 40 characters'],
      minlength: [
        10,
        'A tour name must have greater or equal than 10 character',
      ],
      validate: [validator.isAlpha, 'Tour Name must only contain characters'],
    },

here .isAlpha is a method which allows characters only in the name not even numbers as numbers are not count in character. Not even spaces are not allowed.


************Error handling in nodeJS
We are going to use NDB (node debugger) for error handling
now go to your package.json file and add 

"debug": "ndb server.js" 
in your script tag

now npm run debug

chromium debugger window will be open

This tool is same as chrome debugger but it provides more feature and control. Like chrome debugger you can add break points in it and so on.



***************Handling unhandled route error
// In app.js

app.all('*', (req, res, next) => {
  res.status(404).json({
    status: 'fail',
    message: `Can't find ${req.originalUrl} on this server!`,
  });
});

this is a middleware function for all urls and for all http methods

**IMP**: Don't place middleware in the wrong place as we all know middleware run in the order as they are specified.
So we have defined this middlware in the last of the app.js so that in case of request failure this middleware should reach otherwise it should not.


************Error Handling Overview
There are two types of error
1. Operational Errors (Error which we can predict that may occure at some point somewhere in future e.g invalid path access by the user, failed to connect to the server/database.)
2. Programming Errors (Errors or bugs in our code introduced by the programmer or developer while writing code e.g reading properties from undefined variable)

So to solution to these error we have to create a "Global Error handling middleware" which will deal with error coming from all our application.


**************Implementing Global Error Handling middleware************

// Creating error
app.all('*', (req, res, next) => {
  const err = new Error(`Can't find ${req.originalUrl} on this server!`);
  err.status = 'fail';
  err.statusCode = 404;
  next(err);
});


// Global Error handling middleware
app.use((err, req, res, next) => {
  err.statusCode = err.statusCode || 500;
  err.status = err.status || 'error';
  res.status(err.statusCode).json({
    status: err.status,
    message: err.message,
  });
});

//NOTE: whenever there is middleware with first argument err then Express will automatically assume it as global error handling middleware. And whenever we pass anything inside next(err) function it will be considered that we have passed an error inside next function.

Now we all just need to create error as we have created above then this global middleware will be called automatically.

****************Creating Error Class and refracting the code

//create file in utils called appError.js

// In appError.js
class AppError extends Error {
  constructor(message, statusCode) {
    super(message);

    this.statusCode = statusCode;
    this.status = `${statusCode}`.startsWith('4') ? 'fail' : 'error';
    this.isOperational = true;

    Error.captureStackTrace(this, this.construtor);
  }
}

module.exports = AppError;

// here isOperational = true; would be helpful later on in distinguish between the operational and programming errors

//here we have used the concept of inheritance as AppError inherit inside Error class. In case inheritance we always call super function to call the parent class constructor function. We are calling super function by message property as built Error class only accepts message property.
// stack trace tells you the location of the error as console.log(err.stack)
but in our case we want that whenever a new class is created it should not be traced.	
// we have not done this.message = message as we know super(message) will automatically set the incoming message to message property


//create a new file in controller folder called errorController.js
// In errorController.js

module.exports = (err, req, res, next) => {
  err.statusCode = err.statusCode || 500;
  err.status = err.status || 'error';
  res.status(err.statusCode).json({
    status: err.status,
    message: err.message,
  });
};


//In app.js
const AppError = require('./utils/appError');
const globalErrorHandler = require('./controllers/errorController');

app.all('*', (req, res, next) => {
  next(new AppError(`Can't find ${req.originalUrl} on this server!`, 404));
});

app.use(globalErrorHandler); // this middleware is getting called due to the next function in above middleware.
// This is how we can pass arguments to our Error handling class


**************Catching errors in async Functions
// Create new file in utils folder called catchAsync.js

// In catchAsync.js

module.exports = (fn) => {
  return (req, res, next) => {
    fn(req, res, next).catch((err) => next(err));
  };
};

// we have done this just for the sake to clean our code as there was repeatablity of calling catch block. In order to avoid this we have created a function which receives an other function that function would be our async function.
We are returing a function in this function so that express call it. This is basically a async code work thing.

JS allows to apply catch methods on functions.

now we just have to wrap our async functions in tourController inside this catchAsync function we also have to add next argument property in our async function so that each async function comes with its own next function. Here next(err) will call the global error handling middleware.

// In tourController.js
const catchAsnyc = require('./../utils/catchAsync');
const AppError = require('../utils/appError');

exports.getAllTours = catchAsnyc(async (req, res, next) => {
  // EXECUTE QUERY
  const features = new APIFeatures(Tour.find(), req.query)
    .filter()
    .sort()
    .limitFields()
    .paginate();
  const tours = await features.query;

  res.status(200).json({
    status: 'success',
    results: tours.length,
    data: {
      tours: tours,
    },
  });
});

exports.getTour = catchAsnyc(async (req, res, next) => {
  const tour = await Tour.findById(req.params.id);
  // Tour.findOne({_id: req.params.id})
  if (!tour) {
    return next(new AppError('No Tour Found with this ID', 404));
  }
  res.status(200).json({
    status: 'success',
    data: {
      tour: tour,
    },
  });
});

exports.createTour = catchAsnyc(async (req, res, next) => {
  const newTour = await Tour.create(req.body);
  res.status(200).json({
    status: 'success',
    data: {
      tour: newTour,
    },
  });
});

exports.updateTour = catchAsnyc(async (req, res, next) => {
  const tour = await Tour.findByIdAndUpdate(req.params.id, req.body, {
    new: true,
    runValidators: true,
  });
  if (!tour) {
    return next(new AppError('No Tour Found with this ID', 404));
  }
  res.status(200).json({
    status: 'success',
    data: {
      tour: tour,
    },
  });
});

exports.deleteTour = catchAsnyc(async (req, res, next) => {
  const tour = await Tour.findByIdAndRemove(req.params.id);
  if (!tour) {
    return next(new AppError('No Tour Found with this ID', 404));
  }
  res.status(204).json({
    status: 'success',
    data: null,
  });
});

exports.getTourStats = catchAsnyc(async (req, res, next) => {
  const stats = await Tour.aggregate([
    {
      $match: { ratingsAverage: { $gte: 4.5 } },
    },
    {
      $group: {
        _id: { $toUpper: '$difficulty' },
        // _id: '$ratingsAverage',
        numTours: { $sum: 1 },
        numRating: { $sum: '$ratingsQuantity' },
        avgRating: { $avg: '$ratingsAverage' },
        avgPrice: { $avg: '$price' },
        minPrice: { $min: '$price' },
        maxPrice: { $max: '$price' },
      },
    },
    {
      $sort: {
        avgPrice: 1,
      },
    },
    {
      $match: { _id: { $ne: 'EASY' } },
    },
  ]);

  res.status(200).json({
    status: 'success',
    data: { stats },
  });
});

exports.getMonthlyPlane = catchAsnyc(async (req, res, next) => {
  const year = req.params.year * 1;
  //Deconstructs an array field from the input documents to output a document for each element.
  //Each output document is the input document with the value of the array field replaced by the element.

  const plan = await Tour.aggregate([
    {
      $unwind: '$startDates',
    },
    {
      $match: {
        startDates: {
          $gte: new Date(`${year}-01-2021`),
          $lte: new Date(`${year}-12-31`),
        },
      },
    },
    {
      $group: {
        _id: { $month: '$startDates' },
        numTourStarts: { $sum: 1 },
        tours: { $push: '$name' },
      },
    },
    { $addFields: { month: '$_id' } },
    {
      $project: {
        // project is used for hiding a field
        _id: 0,
      },
    },
    {
      $sort: { numTourStarts: -1 }, //-1 for descending
    },
    {
      $limit: 6, //This is just limiting our number of output documents
    },
  ]);
  res.status(200).json({
    status: 'success',
    data: {
      plan,
    },
  });
});

// NOTE:  See how next(new AppError('No Tour Found with this ID', 404)); 
making our code simple here AppError is just a helper class which make our error more readable and then pass to the next which pass it to our global error handler
	


****************Distinguishing operational and programming errors

// In errorController.js
const sendErrorDev = (err, res) => {
  res.status(err.statusCode).json({
    status: err.status,
    error: err,
    message: err.message,
    stack: err.stack,
  });
};
const sendErrorProd = (err, res) => {
  // operational error that are trusted error: send message to the client
  if (err.isOperational) {
    res.status(err.statusCode).json({
      status: err.status,
      message: err.message,
    });
  
  
  // Programming error or other unknown errors: don't want to leak the details to the client
  } else {
    // 1) log error
    console.error('ERROR 💣', err)

    // send generic error
    res.status(500).json({
      status: 'error',
      message: 'Something went wrong!',
    });
  }
};
module.exports = (err, req, res, next) => {
  err.statusCode = err.statusCode || 500;
  err.status = err.status || 'error';

  if (process.env.NODE_ENV === 'development') {
    sendErrorDev(err, res);
  } else if (process.env.NODE_ENV === 'production') {
    sendErrorProd(err, res);
  }
};


****************Handling errors for Invalid IDs, duplicate field names, mongoose validation error

// In errorcontroller.js
const AppError = require('./../utils/appError');
const handleCastErrorDB = (err) => {
  const message = `Invalid ${err.path}: ${err.value}`;
  return AppError(message, 400);
};
const handleDuplicateFieldsDB = (err) => {
  const value = err.errmsg.match(/(["'])(?:(?=(\\?))\2.)*?\1/)[0];
  console.log(value);
  const message = `Duplicate field value: ${value}. Please use another value`;
  return AppError(message, 400);
};
const handleValidationErrorsDB = (err) => {
  const errors = Object.values(err.errors).map((el) => el.message);
  const message = `Invalid input data ${errors.join('. ')}`;
  return new AppError(message, 400);
};

// REST of the code..

module.exports = (err, req, res, next) => {
  err.statusCode = err.statusCode || 500;
  err.status = err.status || 'error';

  if (process.env.NODE_ENV === 'development') {
    sendErrorDev(err, res);
  } else if (process.env.NODE_ENV === 'production') {
    let error = { ...err }; //trick or creating hard copy
    if (error.name === 'CastError') (error) => handleCastErrorDB(error);
    if (error.code === 11000) (error) => handleDuplicateFieldsDB(error);
    if (error.name === 'ValidationError')
      (error) => handleValidationErrorsDB(error);
    sendErrorProd(error, res);
  }
};


we have made changes for production mode

***********Unhandled promise rejection


There might be a chance that a promise get rejected somewhere in our application but In order to have safety net to prevent that error we use Event listeners

const server = app.listen(port, () => {
  // eslint-disable-next-line no-console
  console.log(`Server is running on port ${port}`);
});

process.on('unhandledRejection', (err) => {
  console.log(err.name, err.message);
  console.log('UNHANDLED REJECTION! Shutting down...');
  server.close(() => {
    process.exit(1);
  });
});


*****************Uncaught Exception
In uncaught exception the termination of application is necessary as in uncaught exception the application is not in the clean state so in such  state application must be terminate but in case of uncaught rejection the termination of applicaion is not necessary

console.log(x)

where x is undefined willl give an uncaught exception.

It should be on the top- of our node js application
even before the app

// In server.js
process.on('uncaughtException', (err) => {
  console.log('UNCAUGHT EXCEPTION');
  process.exit(1);
});



NOTE: Error handling is one of the most complex topic in node js


***********Authentication, Autherization and security

Creating user model and schema

// In models create a file called userModel.js

//In userModel.js

const mongoose = require('mongoose');
const validator = require('validator');

const userSchema = new mongoose.Schema({
  name: {
    type: String,
    require: [true, 'Please tell use your name'],
  },
  email: {
    type: String,
    require: [true, 'Please provide your email'],
    unique: true,
    lowercase: true,
    validate: [validator.isEmail, 'Please provide a valid email'], //isEmail is a builtin function validator npm doucment.
  },
  photo: { type: String, require: true },
  password: {
    type: String,
    require: [true, 'Please provide a password'],
    minlength: 8,
  },
  passwordConfirm: {
    type: String,
    require: [true, 'Please confirm your password'],
  },
});

const User = mongoose.model('User', userSchema); //it will store as users in mongoDB automatically

module.exports = User;


************Creating new Users
Create a file in controller folder called authController.js

//In authController.js

const User = require('./../models/userModel');
const catchAsnyc = require('./../utils/catchAsync');

exports.signup = catchAsnyc(async (req, res) => {
  const newUser = await User.create(req.body);

  res.status(201).json({
    status: 'success',
    data: {
      user: newUser,
    },
  });
});


// Now go to the Routes folder and go to userRouter.js and add a new route
// In userRouter.js


//...Rest of the code

router.post('/signup', authController.signup);

//...Rest of the code

***Testing signup endpoint

go to the postman and check for

127.0.0.1:3000/api/v1/users/signup

// send this below raw json body to this end point with POST method
{
    "name":"test",
    "email":"test@gmail.com",
    "password":"test1234",
    "passwordConfirm":"test1234"
}

**********Managing passwords

We should not store our passowords as plain text in the database as hacker can access them which may cause some damage. So in order to encrypt our passwords we will implement this functionality in our Model not in the controller.
Always follow "Fat model Thin controller"

Go to the userModel.js

First validate the password that the entered password and confirm password both are same. Remember that validation is nothing to work with out DB. We are doing it only for the user to not have any mistake while choosing his password. This means that we are not going save the confirm password field in our database on the actual password field will be stored.

passwordConfirm: {
    type: String,
    require: [true, 'Please confirm your password'],
    validate: {
      //This will work only on saving or creating a user
      validator: function (el) {
        return el === this.password;
      },
      message: 'Passwords are not the same',
    },
  },

// for validation you just have t0 add the above function in your schema

now before storing the password first salt it and then hash it and then store it into the database. here salting before hashing will always create a hased version which won't be the same for same string. This is the power of salting
We are doing this using middleware.

userSchema.pre('save', async function (next) {
  //Only run this function when the password is actually modified
  if (!this.isModified('password')) return next();

  //Hashing the password

  this.password = await bcrypt.hash(this.password, 12);

  //Deleting the confirm password unnecessaary field
  this.passwordConfirm = undefined;
  next();
});

//this middleware will work before the data is going to store in the database.


****************HOW JWT authentcation works
JWT is perfect for RESTful APIs as it matches the principle of stateless.
**General Overview**

Let say, a client made an http post request to login into his account with his email and password. The server first validate the user. If the user is validated then generate a JWT token and sends back to the client. Now this JWT Token is like a passport. Now this token is store in cookies or local storage. Server does not know this JWT token as it is stateless. 
Now onward whenever the user the try to access any protected route the user will send show his JWT token and server will verify it and then will allow access to the user to that proctected route.


JWT:

JWT consists of three parts:
1. Header:

header is simply a meta data or info about the token e.g
{
	"alg": "HS256",
	"type": "JWT"
}


2. Payload
payload is actually the data we want we can decode this data. Remember that this data is not encrypted it is just encoded. e.g
{
	"_id": "5dsfdsc5ds1cscds6sdfdsfsdds4ds5gfham"
}



3. Signature
Signature is made up of three things
header
payload
and a secret key which is stored in our server

e.g

{
	HMACSHA256(base64UrlEncoded(header) + "." + base64UrlEncoded(payload), my-secret-key)
}



JWT = Header + payload + signature
where signature = (header + payload + secret key)

****Deep dive in behind the scenes of how JWT works

when the JWT is received by the client it acts as a passport.

when the user try to access any protected route he shows his JWT token. The verification takes the header and payload and create a Test signature using the secret which is stored in the server. Then the verifier compares only the "Original Signature" with the "Test Signature" if they get matched the user will be allow to access otherwise he won't. Moreover, this verification will also make sure that header and payload are not changed as we all know signature is made up of header, payload and a secret key. 



************Implementing the authenitcation, Signing in the new user:

NOTE: Authentication is the most important part of an application. It should be done very very carefully. For authentication there are several libraries but they do not provide you the full control so therefore we are not going to use any library we will instead write the whole code by ourselves and we will only use one library called "jsonwebtoken" to deal with all JWT stuff.


while generating the secret key most of the developers do mistake they simply make a simple string which is wrong. The secret key must be a 32 character long string which should be complex and not easy to guess.

So I usually prefer to run the below command to generate a random key in the terminal

> require('crypto').randomBytes(32).toString('base64').slice(0,32)

Syntax: require('crypto').randomBytes(size).toString('base64').slice(0,size)

**************Signing up the user and sending JWT back to the client
//In authController.js
const jwt = require('jsonwebtoken');
const User = require('./../models/userModel');
const catchAsnyc = require('./../utils/catchAsync');

exports.signup = catchAsnyc(async (req, res) => {
// here we are receiving only specific data from the client to prevent the unnecessary or harmful data
  const newUser = await User.create({
    name: req.body.name,
    email: req.body.email,
    password: req.body.password,
    passwordConfirm: req.body.passwordConfirm,
  });

//generating jwt
  const token = jwt.sign({ id: newUser._id }, process.env.JWT_SECRET, {
    expiresIn: process.env.JWT_EXPIRES_IN,
  });

//sending back response to the client
  res.status(201).json({
    status: 'success',
    token: token,
    data: {
      user: newUser,
    },
  });
});

// Here we are simply singing up/ creating a new user so there is no any need here to verify the user. In the next step we are going to implement this.


************Logging the user In
// creating a login route in userRoute.js

//In userRoutes.js

router.post('/login', authController.login);


//In authController.js
const jwt = require('jsonwebtoken');
const User = require('./../models/userModel');
const catchAsnyc = require('./../utils/catchAsync');
const AppError = require('./../utils/appError');

const signToken = (id) => {
  return jwt.sign({ id: id }, process.env.JWT_SECRET, {
    expiresIn: process.env.JWT_EXPIRES_IN,
  });
};

exports.login = catchAsnyc(async (req, res, next) => {
  const { email, password } = req.body;

  //checking email and password exists or not

  if (!email || !password) {
    return next(new AppError('Please provide email and password!', 400));
  }

  // Checking the user exist and password is correct.
  const user = await User.findOne({ email: email }).select('+password'); //here + sign is for the fields which are by default not selected in User Model as select:false

  //here correctPassword is our custom made global instance method for user document thats why we can use it here.
  if (!user || !(await user.correctPassword(password, user.password))) {
    return next(new AppError('incorrect email or password', 401));
  }

  // If everything ok, then send token to client
  const token = signToken(user._id);
  res.status(200).json({
    status: 'success',
    token: token,
  });
});

// here correct password is a custom method which we have created it is called global instance method which we have created in userModel.js we could create this method any where but we are following fat model and thin controller principle so thats why...

// so in UserModel.js

userSchema.methods.correctPassword = async function (candidatePassword, userPassword) {
  return await bcrypt.compare(candidatePassword, userPassword);
};

also we do not want our password visible when we do getAllUser request so to prevent it we are adding the following property in our model schema
 password: {
    type: String,
    require: [true, 'Please provide a password'],
    minlength: 8,
    select: false,
  },

//Here till this point a user logged in get authorized and get a jwtToken now our next step would be to protect our routes

***************Protecting the routes Part 1
here we want to protect the getAllUser route which we can protect by using middleware

//In authController.js
exports.protect = catchAsnyc(async (req, res, next) => {
  //Getting the token and check its true or not
  let token;
  if (
    req.headers.authorization &&
    req.headers.authorization.startsWith('Bearer')
  ) {
    token = req.headers.authorization.split(' ')[1];
  }
  console.log('My Token: ', token);

  if (!token) {
    return next(
      new AppError(
        'You are not logged in! Please log in first to get access',
        401,
      ),
    );
  }
  next();

  //verification of token
  //check if user is still exists
  //check if user changed password after the token was issued
});

//In tourRoutes.js
const authController = require('../controllers/authController');

//Rest of the code.....

  .route('/')
  .get(authController.protect, tourController.getAllTours)
  .post(tourController.createTour);



**********Now complete authenticaion 

// In authController.js
exports.login = catchAsnyc(async (req, res, next) => {
  const { email, password } = req.body;

  //checking email and password exists or not

  if (!email || !password) {
    return next(new AppError('Please provide email and password!', 400));
  }

  // Checking the user exist and password is correct.
  const user = await User.findOne({ email: email }).select('+password'); //here + sign is for the fields which are by default not selected in User Model as select:false

  //here correctPassword is our custom made global instance method for user document thats why we can use it here.
  if (!user || !(await user.correctPassword(password, user.password))) {
    return next(new AppError('incorrect email or password', 401));
  }

  // If everything ok, then send token to client
  const token = signToken(user._id);
  res.status(200).json({
    status: 'success',
    token: token,
  });
});

exports.protect = catchAsnyc(async (req, res, next) => {
  //Getting the token and check its true or not
  let token;
  if (
    req.headers.authorization &&
    req.headers.authorization.startsWith('Bearer')
  ) {
    token = req.headers.authorization.split(' ')[1];
  }
  console.log('My Token: ', token);

  if (!token) {
    return next(
      new AppError(
        'You are not logged in! Please log in first to get access',
        401,
      ),
    );
  }

  //verification of token
  const decoded = await promisify(jwt.verify)(token, process.env.JWT_SECRET);

  //check if user is still exists
  const freshUser = await User.findById(decoded.id);
  if (!freshUser) {
    return next(
      new AppError(
        'The token belonging to this user no longer exist. Please login again!',
        401,
      ),
    );
  }

  //check if user changed password after the token was issued
  if (freshUser.changedPasswordAfter(decoded.iat)) {
    return next(
      new AppError('User recently changed password. Please log in again', 401),
    );
  }

  //Grant access to protected route
  req.user = freshUser; //assigning current user to req.user to have access to the current user. This is very very important step
  next();
});

**NOTE**:   req.user = freshUser; //assigning current user to req.user to have access to the current user. This is very very important step


// In userModel.js

userSchema.methods.changedPasswordAfter = function (JWTTimestamp) {
  if (this.passwordChangedAt) {
    const changedTimeStamp = parseInt(
      this.passwordChangedAt.getTime() / 1000,
      10,
    );
    return JWTTimestamp < changedTimeStamp;
  }

  //false means password not changed
  return false;
};


//most of the developer only do authentication algorithm till verification of token. They do not do complete authentication till check if user changed password after the token was issued this is supposed to be done as if someone stole the JWT token of a user and the user to protect himself change his password then the token should also be expired a new token should be generate right? so in this we have done that too. Moreover we have also checked if user is still exists. This is done so that in a case when someone deleted the user from the database and then its token will be there and due to which someone can grant access to the protected routes which should be done. We have deal with this case too.


While access the protecting routes the user must send valid JWT token via headers so in postman go to headers and give key, value as
authorization: Bearer ashfgsadhfdsajasjkd8236482e27e632876217g


*************Advance Postman Setup
First we will setup our environment
we have set two environments namely Dev: Natours and Prod: Natours
we have set URL: http://127.0.0.1 for Dev env
we have set URL: natours.io for Prod env


Now we all know that on login or on creating a new user that is signing up we get a JWT Token and then we send this token from front end inside the headers to get access to the protected routes.
so here we were doing copy and paste the token to test our end points so save out time we will automate this process

so to do that go to your signup and login end points tab in Postman and look for test tab and write a code to programmatically automate the process.
In sigup test script

pm.environment.set("jwt", pm.response.json().token);

In login test script
pm.environment.set("jwt", pm.response.json().token);

//here we are assigning our coming token to jwt variable which would be available through out the environment in postman

now go to your getAllTours tab
look for authorization tab and select Bearer Token and set token to {{jwt}}

************Implenmenting Authorization and role based permissions
Authenticaiton and Authorization both are different things.
Authentication verifies the identity of a user whereas authorization determines the right of access on the basis of the role of the user.

All logged in users are not allowed to perform all the actions in the API only certain users such as admin etc will be allowed to have full control.

So we are first gonna restrict out DeleteTour route, only admin and lead-guide would be allowed to do this.

so to do that first create wrapper function which returns a middleware function 

//In authCOntroller.js
exports.restrictTo = (...roles) => {
  return (req, res, next) => {
    // where roles = ['admin', 'lead-guie'] are allowed
    console.log('roles: ', roles);
    if (!roles.includes(req.user.role)) {
      return next(
        new AppError('You are not have permission to perform this action', 403),
      );
    }
    next();
  };
};
// here we cannot pass aurguments to a middleware function thats why we are wrapping our middleware function
// into a restrictTo wrapper function
// here req.user is the current user as we have stored our current user in req.user in protect route middleware function

//In tourRoutes.js

//Rest of the code....
router
  .route('/:id')
  .get(tourController.getTour)
  .patch(tourController.updateTour)
  .delete(
    authController.protect,
    authController.restrictTo('admin', 'lead-guide'),
    tourController.deleteTour,
  );


here in delete tour route we have introduced two middleware first middlware is protecting the route from unauthenticated user and second one is authorizing the user
NOTE that we are passing two arguments in restrictTo wrapper function which returns a middleware function


****************Reset Password functionality or Fogot password
So here in this functionality there are two methods to implement this 
step 1: The user will send a post request to forgot password route where he will provide an email address. 
Then a reset token will be generated which will not a JSON token but a simple token. That token will be send to the provided email address.
Step 2: User will send back or make a post request to the reset password route with that reset token along with his new or updated password.

*****Step1

Here one thing the you should always remember that the reset token should be encrypted first and then save into the database. Whereas the non encrypted version of the token should be send to cliend via email.
When ever there is a need of function which will must interact with the database or our shema model we always refer to have global instance method functions in our Model.js

// In userModel.js

passwordResetToken: String,
passwordResetExpires: Date,

//add these above two fields in your model schema

userSchema.methods.createPasswordResetToken = function () {
  // generating a token
  const resetToken = crypto.randomBytes(32).toString('hex');

  // encypting the generated token and storing into our database

  this.passwordResetToken = crypto
    .createHash('sha256')
    .update(resetToken)
    .digest('hex');

  console.log({ resetToken }, this.passwordResetToken);
  this.passwordResetExpires = Date.now() + 10 * 60 * 1000;

  return resetToken;
};

// this global instance method will return an unencrypted reset Token and will save an encypted reset token to the database so that later we could compare them. Moreover since this is a global instance method so this would be available through out the document. This key word here will point toward the current document that why to access any field we do this.passwordResetToken

// In userRoutes.js
// Don't forget to create routes for forgot and reset password

router.post('/forgotPassword', authController.forgotPassword);
router.patch('/resetPassword/:token', authController.resetPassword);

// In authConroller.js
exports.forgotPassword = catchAsnyc(async (req, res, next) => {
  // Get the user email tand verify the email
  const user = await User.findOne({ email: req.body.email });
  if (!user) {
    return next(new AppError('There is no user with this email address!', 404));
  }
  // Generate a random token
  const resetToken = user.createPasswordResetToken();
  await user.save({ validateBeforeSave: false });

  // Send that token to the provided email
});

NOTE: here the reason behind using this property { validateBeforeSave: false } is that we are saving encrypted version of resetPassword Token without any validation we are assuming it to correct as we are generating it by ourselve. So here we will get warnings and error so we are just turning off validation for this token saving in database.

**************Sending email/ Forgot Password
To send email via node js we are using nodemailer and for development instead of using our actual emails we are using mailtrap to deal with emails. This mail trap will give us a fake email and password to which we can send emails etc.

// In authController.js

exports.forgotPassword = catchAsnyc(async (req, res, next) => {
  // Get the user email tand verify the email
  const user = await User.findOne({ email: req.body.email });
  if (!user) {
    return next(new AppError('There is no user with this email address!', 404));
  }
  // Generate a random token
  const resetToken = user.createPasswordResetToken();
  await user.save({ validateBeforeSave: false });

  // Send that token to the provided email
  const resetURL = `${req.protocol}://${req.get(
    'host',
  )}/api/v1/users/resetPassword/${resetToken}`;

  const message = `Forgot your password? Submit a PATCH request with your new password and confirm password to: ${resetURL}.\nIf you didn't forget your password then Please ignore this email.`;
  try {
    await sendEmail({
      email: user.email,
      subject: 'You Password Reset Token (Valid for 10 mins)',
      message: message,
    });

    res.status(200).json({
      status: 'success',
      message: 'Token sent to email!',
    });
  } catch (err) {
    (user.passwordResetToken = undefined),
      (user.passwordResetExpires = undefined),
      await user.save({ validateBeforeSave: false });
    return next(
      new AppError(
        'There was an error in sending the email. Try again later!',
        500,
      ),
    );
  }
});

// Here we have completed our three step forgot password mechanism. In catch block in case of any error we have set our generated reset tokens to undefined.

// In utils folder email.js
const nodemailer = require('nodemailer');

const sendEmail = async (options) => {
  // 1) Create a transporter
  const transporter = nodemailer.createTransport({
    host: process.env.EMAIL_HOST,
    port: process.env.EMAIL_PORT,
    auth: {
      user: process.env.EMAIL_USERNAME,
      pass: process.env.EMAIL_PASSWORD,
    },
  });
  // Define email option
  const mailOptions = {
    from: 'Jonas Schmedtmann <user@gmail.com>',
    to: options.email,
    subject: options.subject,
    text: options.message,
  };
  // Actually send email
  await transporter.sendMail(mailOptions);
};

module.exports = sendEmail;

// Here we are simply configuring our mail sending mechanism. Here from now we will work on resetting the password.
Uptill now when the user will click on forgot password a user will be validate first after that a token will be generated and its encrypted version will be saved in the database and its unencrypted version will be sent to the email using nodemailer and mailtrap to user. Now the user will go to the reset route with reset token he got in the email and then he send back the token with updated password. Then the password will be compared with the encrypted version saved in the database if it get matched then password will be updated otherwise not.

*****************Resetting the password.







